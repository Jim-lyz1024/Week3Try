*** Config ***
***************
** Arguments **
***************
dataset: Digits
gpu: 0
model: CLIPAdapter
model_config_file: config/clipadapter.yaml
output_dir: output/CLIPAdapter-ViTB32-Digits-mnist
root: ./data/
seed: 134
source_domains: ['mnist_m', 'svhn', 'syn']
target_domains: ['mnist']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 64
    SAMPLER: RandomSampler
DATASET:
  NAME: Digits
  ROOT: ./data/
  SOURCE_DOMAINS: ['mnist_m', 'svhn', 'syn']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['mnist']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  CLIPAdapter:
    BACKBONE: ViT-B/32
  NAME: CLIPAdapter
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: Cosine
  MAX_EPOCH: 5
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: -1
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/CLIPAdapter-ViTB32-Digits-mnist
SEED: 134
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: CLIPAdapter
Build Dataset: Digits
File Extracted to /home/yil708/data/yil708/Week3Try/data
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  --------------------------
Dataset         Digits
Source Domains  ['mnist_m', 'svhn', 'syn']
Target Domains  ['mnist']
# Classes       10
# Train Data    18,000
# Val Data      3,600
# Test Data     6,000
--------------  --------------------------
Loading CLIP Backbone: ViT-B/32
Building Custom CLIP
Domains:  ['mnist', 'mnist_m', 'svhn', 'syn']
Prompts: ['a picture of a mnist 0.', 'a picture of a mnist 1.', 'a picture of a mnist 2.', 'a picture of a mnist 3.', 'a picture of a mnist 4.', 'a picture of a mnist 5.', 'a picture of a mnist 6.', 'a picture of a mnist 7.', 'a picture of a mnist 8.', 'a picture of a mnist 9.', 'a picture of a mnist_m 0.', 'a picture of a mnist_m 1.', 'a picture of a mnist_m 2.', 'a picture of a mnist_m 3.', 'a picture of a mnist_m 4.', 'a picture of a mnist_m 5.', 'a picture of a mnist_m 6.', 'a picture of a mnist_m 7.', 'a picture of a mnist_m 8.', 'a picture of a mnist_m 9.', 'a picture of a svhn 0.', 'a picture of a svhn 1.', 'a picture of a svhn 2.', 'a picture of a svhn 3.', 'a picture of a svhn 4.', 'a picture of a svhn 5.', 'a picture of a svhn 6.', 'a picture of a svhn 7.', 'a picture of a svhn 8.', 'a picture of a svhn 9.', 'a picture of a syn 0.', 'a picture of a syn 1.', 'a picture of a syn 2.', 'a picture of a syn 3.', 'a picture of a syn 4.', 'a picture of a syn 5.', 'a picture of a syn 6.', 'a picture of a syn 7.', 'a picture of a syn 8.', 'a picture of a syn 9.']
Turning Off Gradients in Image and Text Encoder
Parameters to be updated: {'adapter.fc.0.weight', 'adapter.fc.2.weight'}
Build Evaluator: Classification
epoch [1/5] batch [5/281] loss 3.6309 (3.5199) acc 0.0000 (3.7500) lr 1.0000e-05 eta 0:08:21
epoch [1/5] batch [10/281] loss 3.5039 (3.5422) acc 4.6875 (3.1250) lr 1.0000e-05 eta 0:04:25
epoch [1/5] batch [15/281] loss 3.5938 (3.5529) acc 3.1250 (3.3333) lr 1.0000e-05 eta 0:03:06
epoch [1/5] batch [20/281] loss 3.5469 (3.5479) acc 4.6875 (3.5156) lr 1.0000e-05 eta 0:02:27
epoch [1/5] batch [25/281] loss 3.6562 (3.5573) acc 1.5625 (3.1250) lr 1.0000e-05 eta 0:02:03
epoch [1/5] batch [30/281] loss 3.5684 (3.5540) acc 1.5625 (3.1250) lr 1.0000e-05 eta 0:01:47
epoch [1/5] batch [35/281] loss 3.5820 (3.5613) acc 9.3750 (3.2589) lr 1.0000e-05 eta 0:01:35
epoch [1/5] batch [40/281] loss 3.6074 (3.5673) acc 3.1250 (3.2422) lr 1.0000e-05 eta 0:01:27
epoch [1/5] batch [45/281] loss 3.5801 (3.5689) acc 1.5625 (3.1250) lr 1.0000e-05 eta 0:01:20
epoch [1/5] batch [50/281] loss 3.6094 (3.5722) acc 6.2500 (3.1562) lr 1.0000e-05 eta 0:01:15
epoch [1/5] batch [55/281] loss 3.7188 (3.5733) acc 1.5625 (3.2102) lr 1.0000e-05 eta 0:01:10
epoch [1/5] batch [60/281] loss 3.6426 (3.5725) acc 0.0000 (3.1510) lr 1.0000e-05 eta 0:01:07
epoch [1/5] batch [65/281] loss 3.5488 (3.5697) acc 3.1250 (3.0529) lr 1.0000e-05 eta 0:01:04
epoch [1/5] batch [70/281] loss 3.6738 (3.5733) acc 3.1250 (3.0804) lr 1.0000e-05 eta 0:01:01
epoch [1/5] batch [75/281] loss 3.5391 (3.5759) acc 3.1250 (3.0417) lr 1.0000e-05 eta 0:00:58
epoch [1/5] batch [80/281] loss 3.5762 (3.5766) acc 3.1250 (3.0664) lr 1.0000e-05 eta 0:00:56
epoch [1/5] batch [85/281] loss 3.5469 (3.5789) acc 3.1250 (3.0699) lr 1.0000e-05 eta 0:00:55
epoch [1/5] batch [90/281] loss 3.4648 (3.5784) acc 6.2500 (3.0556) lr 1.0000e-05 eta 0:00:53
epoch [1/5] batch [95/281] loss 3.6895 (3.5814) acc 1.5625 (3.0428) lr 1.0000e-05 eta 0:00:51
epoch [1/5] batch [100/281] loss 3.5410 (3.5797) acc 4.6875 (3.1406) lr 1.0000e-05 eta 0:00:50
epoch [1/5] batch [105/281] loss 3.4863 (3.5788) acc 1.5625 (3.0804) lr 1.0000e-05 eta 0:00:49
epoch [1/5] batch [110/281] loss 3.6191 (3.5766) acc 6.2500 (3.1250) lr 1.0000e-05 eta 0:00:48
epoch [1/5] batch [115/281] loss 3.6309 (3.5779) acc 7.8125 (3.1793) lr 1.0000e-05 eta 0:00:47
epoch [1/5] batch [120/281] loss 3.6758 (3.5806) acc 4.6875 (3.1771) lr 1.0000e-05 eta 0:00:46
epoch [1/5] batch [125/281] loss 3.5586 (3.5817) acc 3.1250 (3.1750) lr 1.0000e-05 eta 0:00:45
epoch [1/5] batch [130/281] loss 3.5273 (3.5830) acc 4.6875 (3.1611) lr 1.0000e-05 eta 0:00:44
epoch [1/5] batch [135/281] loss 3.6152 (3.5818) acc 6.2500 (3.2176) lr 1.0000e-05 eta 0:00:43
epoch [1/5] batch [140/281] loss 3.5996 (3.5812) acc 1.5625 (3.1808) lr 1.0000e-05 eta 0:00:42
epoch [1/5] batch [145/281] loss 3.4824 (3.5811) acc 0.0000 (3.1789) lr 1.0000e-05 eta 0:00:42
epoch [1/5] batch [150/281] loss 3.5254 (3.5813) acc 3.1250 (3.1771) lr 1.0000e-05 eta 0:00:41
epoch [1/5] batch [155/281] loss 3.5527 (3.5829) acc 3.1250 (3.1351) lr 1.0000e-05 eta 0:00:40
epoch [1/5] batch [160/281] loss 3.4902 (3.5807) acc 7.8125 (3.1738) lr 1.0000e-05 eta 0:00:40
epoch [1/5] batch [165/281] loss 3.5410 (3.5810) acc 1.5625 (3.1913) lr 1.0000e-05 eta 0:00:39
epoch [1/5] batch [170/281] loss 3.5039 (3.5789) acc 3.1250 (3.2537) lr 1.0000e-05 eta 0:00:39
epoch [1/5] batch [175/281] loss 3.5625 (3.5778) acc 3.1250 (3.2589) lr 1.0000e-05 eta 0:00:38
epoch [1/5] batch [180/281] loss 3.5898 (3.5780) acc 1.5625 (3.2292) lr 1.0000e-05 eta 0:00:38
epoch [1/5] batch [185/281] loss 3.5273 (3.5786) acc 4.6875 (3.2348) lr 1.0000e-05 eta 0:00:37
epoch [1/5] batch [190/281] loss 3.7148 (3.5799) acc 1.5625 (3.2484) lr 1.0000e-05 eta 0:00:37
epoch [1/5] batch [195/281] loss 3.6602 (3.5810) acc 0.0000 (3.1731) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [200/281] loss 3.6367 (3.5806) acc 4.6875 (3.2031) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [205/281] loss 3.5820 (3.5811) acc 0.0000 (3.1479) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [210/281] loss 3.5352 (3.5813) acc 3.1250 (3.1176) lr 1.0000e-05 eta 0:00:35
epoch [1/5] batch [215/281] loss 3.5664 (3.5809) acc 1.5625 (3.0887) lr 1.0000e-05 eta 0:00:35
epoch [1/5] batch [220/281] loss 3.5840 (3.5810) acc 4.6875 (3.0682) lr 1.0000e-05 eta 0:00:35
epoch [1/5] batch [225/281] loss 3.5508 (3.5809) acc 3.1250 (3.0417) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [230/281] loss 3.5996 (3.5825) acc 7.8125 (3.0503) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [235/281] loss 3.4355 (3.5815) acc 1.5625 (3.0386) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [240/281] loss 3.6699 (3.5819) acc 0.0000 (3.0469) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [245/281] loss 3.5723 (3.5809) acc 1.5625 (3.0612) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [250/281] loss 3.4746 (3.5805) acc 4.6875 (3.0812) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [255/281] loss 3.6602 (3.5799) acc 3.1250 (3.1127) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [260/281] loss 3.6367 (3.5807) acc 1.5625 (3.0709) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [265/281] loss 3.6348 (3.5807) acc 3.1250 (3.0660) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [270/281] loss 3.5273 (3.5803) acc 1.5625 (3.0903) lr 1.0000e-05 eta 0:00:31
epoch [1/5] batch [275/281] loss 3.5938 (3.5801) acc 4.6875 (3.0852) lr 1.0000e-05 eta 0:00:31
epoch [1/5] batch [280/281] loss 3.7188 (3.5805) acc 1.5625 (3.0748) lr 1.0000e-05 eta 0:00:31
epoch [2/5] batch [5/281] loss 3.5215 (3.5145) acc 3.1250 (3.4375) lr 2.0000e-03 eta 0:02:37
epoch [2/5] batch [10/281] loss 3.3281 (3.4693) acc 6.2500 (3.7500) lr 2.0000e-03 eta 0:01:30
epoch [2/5] batch [15/281] loss 3.4102 (3.4587) acc 4.6875 (3.3333) lr 2.0000e-03 eta 0:01:08
epoch [2/5] batch [20/281] loss 3.1992 (3.4129) acc 3.1250 (3.8281) lr 2.0000e-03 eta 0:00:56
epoch [2/5] batch [25/281] loss 3.1562 (3.3689) acc 4.6875 (4.1250) lr 2.0000e-03 eta 0:00:50
epoch [2/5] batch [30/281] loss 3.0371 (3.3159) acc 4.6875 (4.4271) lr 2.0000e-03 eta 0:00:45
epoch [2/5] batch [35/281] loss 2.8809 (3.2617) acc 6.2500 (5.1339) lr 2.0000e-03 eta 0:00:42
epoch [2/5] batch [40/281] loss 2.7363 (3.2051) acc 7.8125 (5.8594) lr 2.0000e-03 eta 0:00:39
epoch [2/5] batch [45/281] loss 2.6680 (3.1490) acc 12.5000 (6.6667) lr 2.0000e-03 eta 0:00:37
epoch [2/5] batch [50/281] loss 2.5840 (3.0941) acc 17.1875 (7.6562) lr 2.0000e-03 eta 0:00:36
epoch [2/5] batch [55/281] loss 2.5801 (3.0458) acc 9.3750 (7.8409) lr 2.0000e-03 eta 0:00:34
epoch [2/5] batch [60/281] loss 2.4219 (2.9983) acc 26.5625 (8.5156) lr 2.0000e-03 eta 0:00:33
epoch [2/5] batch [65/281] loss 2.4102 (2.9549) acc 9.3750 (8.7740) lr 2.0000e-03 eta 0:00:32
epoch [2/5] batch [70/281] loss 2.4004 (2.9159) acc 12.5000 (8.8393) lr 2.0000e-03 eta 0:00:32
epoch [2/5] batch [75/281] loss 2.3848 (2.8799) acc 10.9375 (9.0417) lr 2.0000e-03 eta 0:00:31
epoch [2/5] batch [80/281] loss 2.3867 (2.8489) acc 10.9375 (9.1992) lr 2.0000e-03 eta 0:00:30
epoch [2/5] batch [85/281] loss 2.3340 (2.8215) acc 17.1875 (9.2647) lr 2.0000e-03 eta 0:00:30
epoch [2/5] batch [90/281] loss 2.3145 (2.7954) acc 14.0625 (9.3056) lr 2.0000e-03 eta 0:00:29
epoch [2/5] batch [95/281] loss 2.3398 (2.7725) acc 15.6250 (9.3586) lr 2.0000e-03 eta 0:00:29
epoch [2/5] batch [100/281] loss 2.3691 (2.7507) acc 12.5000 (9.5312) lr 2.0000e-03 eta 0:00:28
epoch [2/5] batch [105/281] loss 2.3633 (2.7318) acc 7.8125 (9.6577) lr 2.0000e-03 eta 0:00:28
epoch [2/5] batch [110/281] loss 2.3574 (2.7145) acc 9.3750 (9.6165) lr 2.0000e-03 eta 0:00:27
epoch [2/5] batch [115/281] loss 2.3477 (2.6980) acc 12.5000 (9.7826) lr 2.0000e-03 eta 0:00:27
epoch [2/5] batch [120/281] loss 2.3438 (2.6835) acc 10.9375 (9.9219) lr 2.0000e-03 eta 0:00:27
epoch [2/5] batch [125/281] loss 2.3105 (2.6689) acc 14.0625 (9.9750) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [130/281] loss 2.3281 (2.6560) acc 14.0625 (10.1082) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [135/281] loss 2.3262 (2.6444) acc 9.3750 (10.0810) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [140/281] loss 2.3281 (2.6332) acc 12.5000 (10.0558) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [145/281] loss 2.3105 (2.6223) acc 7.8125 (10.1185) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [150/281] loss 2.2812 (2.6114) acc 14.0625 (10.2708) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [155/281] loss 2.3359 (2.6028) acc 6.2500 (10.2016) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [160/281] loss 2.3418 (2.5940) acc 6.2500 (10.2148) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [165/281] loss 2.3145 (2.5855) acc 14.0625 (10.2273) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [170/281] loss 2.3047 (2.5771) acc 14.0625 (10.3493) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [175/281] loss 2.3242 (2.5695) acc 7.8125 (10.3482) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [180/281] loss 2.2832 (2.5622) acc 12.5000 (10.4167) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [185/281] loss 2.3398 (2.5556) acc 12.5000 (10.4392) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [190/281] loss 2.3281 (2.5487) acc 7.8125 (10.5839) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [195/281] loss 2.3340 (2.5430) acc 9.3750 (10.5529) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [200/281] loss 2.3535 (2.5375) acc 6.2500 (10.5547) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [205/281] loss 2.3301 (2.5320) acc 17.1875 (10.6326) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [210/281] loss 2.3105 (2.5265) acc 15.6250 (10.6920) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [215/281] loss 2.3047 (2.5213) acc 14.0625 (10.7122) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [220/281] loss 2.2910 (2.5165) acc 4.6875 (10.7031) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [225/281] loss 2.3145 (2.5115) acc 15.6250 (10.8264) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [230/281] loss 2.2676 (2.5069) acc 14.0625 (10.9103) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [235/281] loss 2.2754 (2.5022) acc 15.6250 (10.9707) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [240/281] loss 2.2832 (2.4976) acc 15.6250 (11.0417) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [245/281] loss 2.3066 (2.4937) acc 14.0625 (11.0778) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [250/281] loss 2.3066 (2.4900) acc 15.6250 (11.0750) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [255/281] loss 2.2500 (2.4861) acc 15.6250 (11.1581) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [260/281] loss 2.2969 (2.4824) acc 15.6250 (11.2200) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [265/281] loss 2.3672 (2.4794) acc 4.6875 (11.1380) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [270/281] loss 2.2949 (2.4758) acc 15.6250 (11.2095) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [275/281] loss 2.3281 (2.4729) acc 14.0625 (11.2216) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [280/281] loss 2.2969 (2.4698) acc 14.0625 (11.2333) lr 2.0000e-03 eta 0:00:20
epoch [3/5] batch [5/281] loss 2.2148 (2.2770) acc 21.8750 (13.7500) lr 1.8090e-03 eta 0:01:53
epoch [3/5] batch [10/281] loss 2.2832 (2.2877) acc 9.3750 (12.5000) lr 1.8090e-03 eta 0:01:05
epoch [3/5] batch [15/281] loss 2.2832 (2.2921) acc 15.6250 (12.3958) lr 1.8090e-03 eta 0:00:49
epoch [3/5] batch [20/281] loss 2.2559 (2.2891) acc 14.0625 (12.9688) lr 1.8090e-03 eta 0:00:41
epoch [3/5] batch [25/281] loss 2.2773 (2.2881) acc 20.3125 (13.0625) lr 1.8090e-03 eta 0:00:36
epoch [3/5] batch [30/281] loss 2.2305 (2.2865) acc 10.9375 (12.9688) lr 1.8090e-03 eta 0:00:33
epoch [3/5] batch [35/281] loss 2.3086 (2.2884) acc 14.0625 (12.9018) lr 1.8090e-03 eta 0:00:30
epoch [3/5] batch [40/281] loss 2.3086 (2.2902) acc 12.5000 (12.6562) lr 1.8090e-03 eta 0:00:29
epoch [3/5] batch [45/281] loss 2.2695 (2.2921) acc 14.0625 (12.4653) lr 1.8090e-03 eta 0:00:27
epoch [3/5] batch [50/281] loss 2.3145 (2.2924) acc 10.9375 (12.5625) lr 1.8090e-03 eta 0:00:26
epoch [3/5] batch [55/281] loss 2.3184 (2.2937) acc 6.2500 (12.2443) lr 1.8090e-03 eta 0:00:25
epoch [3/5] batch [60/281] loss 2.3340 (2.2945) acc 7.8125 (12.2917) lr 1.8090e-03 eta 0:00:24
epoch [3/5] batch [65/281] loss 2.3203 (2.2941) acc 7.8125 (12.4279) lr 1.8090e-03 eta 0:00:24
epoch [3/5] batch [70/281] loss 2.2871 (2.2948) acc 15.6250 (12.4330) lr 1.8090e-03 eta 0:00:23
epoch [3/5] batch [75/281] loss 2.2637 (2.2942) acc 15.6250 (12.4375) lr 1.8090e-03 eta 0:00:22
epoch [3/5] batch [80/281] loss 2.3164 (2.2938) acc 10.9375 (12.4609) lr 1.8090e-03 eta 0:00:22
epoch [3/5] batch [85/281] loss 2.2754 (2.2942) acc 9.3750 (12.4265) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [90/281] loss 2.2598 (2.2939) acc 17.1875 (12.4306) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [95/281] loss 2.2793 (2.2938) acc 15.6250 (12.4507) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [100/281] loss 2.3262 (2.2938) acc 4.6875 (12.3750) lr 1.8090e-03 eta 0:00:20
epoch [3/5] batch [105/281] loss 2.3027 (2.2943) acc 14.0625 (12.4107) lr 1.8090e-03 eta 0:00:20
epoch [3/5] batch [110/281] loss 2.2773 (2.2942) acc 17.1875 (12.4716) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [115/281] loss 2.2930 (2.2941) acc 21.8750 (12.5272) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [120/281] loss 2.3145 (2.2948) acc 7.8125 (12.4089) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [125/281] loss 2.2773 (2.2952) acc 17.1875 (12.3500) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [130/281] loss 2.3359 (2.2956) acc 7.8125 (12.2716) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [135/281] loss 2.2793 (2.2958) acc 14.0625 (12.2685) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [140/281] loss 2.3027 (2.2964) acc 4.6875 (12.1875) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [145/281] loss 2.3008 (2.2964) acc 6.2500 (12.1336) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [150/281] loss 2.2598 (2.2958) acc 23.4375 (12.3021) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [155/281] loss 2.2598 (2.2955) acc 14.0625 (12.3589) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [160/281] loss 2.2793 (2.2953) acc 18.7500 (12.4707) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [165/281] loss 2.2715 (2.2951) acc 15.6250 (12.5568) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [170/281] loss 2.3027 (2.2953) acc 17.1875 (12.5827) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [175/281] loss 2.2715 (2.2948) acc 14.0625 (12.6964) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [180/281] loss 2.2754 (2.2942) acc 23.4375 (12.8733) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [185/281] loss 2.2617 (2.2937) acc 21.8750 (12.9730) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [190/281] loss 2.3242 (2.2934) acc 10.9375 (13.0510) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [195/281] loss 2.2949 (2.2933) acc 17.1875 (13.0288) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [200/281] loss 2.3066 (2.2935) acc 9.3750 (13.0000) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [205/281] loss 2.3184 (2.2935) acc 6.2500 (13.0107) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [210/281] loss 2.2969 (2.2936) acc 9.3750 (12.9911) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [215/281] loss 2.3164 (2.2937) acc 4.6875 (12.9142) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [220/281] loss 2.3105 (2.2939) acc 14.0625 (12.8906) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [225/281] loss 2.3008 (2.2941) acc 15.6250 (12.8889) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [230/281] loss 2.2695 (2.2938) acc 20.3125 (12.9280) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [235/281] loss 2.2812 (2.2936) acc 14.0625 (12.9721) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [240/281] loss 2.2988 (2.2934) acc 10.9375 (13.0469) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [245/281] loss 2.2930 (2.2933) acc 9.3750 (13.0230) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [250/281] loss 2.2598 (2.2931) acc 12.5000 (13.0250) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [255/281] loss 2.2793 (2.2930) acc 10.9375 (13.0699) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [260/281] loss 2.3027 (2.2928) acc 15.6250 (13.0589) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [265/281] loss 2.2949 (2.2928) acc 15.6250 (13.0719) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [270/281] loss 2.2441 (2.2924) acc 17.1875 (13.1192) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [275/281] loss 2.2988 (2.2922) acc 9.3750 (13.1080) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [280/281] loss 2.2988 (2.2923) acc 15.6250 (13.1083) lr 1.8090e-03 eta 0:00:13
epoch [4/5] batch [5/281] loss 2.2773 (2.2785) acc 17.1875 (17.5000) lr 1.3090e-03 eta 0:01:08
epoch [4/5] batch [10/281] loss 2.2656 (2.2766) acc 12.5000 (15.1562) lr 1.3090e-03 eta 0:00:39
epoch [4/5] batch [15/281] loss 2.3145 (2.2767) acc 7.8125 (15.2083) lr 1.3090e-03 eta 0:00:30
epoch [4/5] batch [20/281] loss 2.2754 (2.2784) acc 15.6250 (15.5469) lr 1.3090e-03 eta 0:00:25
epoch [4/5] batch [25/281] loss 2.2832 (2.2813) acc 20.3125 (15.4375) lr 1.3090e-03 eta 0:00:22
epoch [4/5] batch [30/281] loss 2.3066 (2.2856) acc 10.9375 (14.6875) lr 1.3090e-03 eta 0:00:20
epoch [4/5] batch [35/281] loss 2.3320 (2.2882) acc 4.6875 (14.2857) lr 1.3090e-03 eta 0:00:19
epoch [4/5] batch [40/281] loss 2.2930 (2.2907) acc 17.1875 (14.1797) lr 1.3090e-03 eta 0:00:18
epoch [4/5] batch [45/281] loss 2.2773 (2.2899) acc 14.0625 (14.0972) lr 1.3090e-03 eta 0:00:17
epoch [4/5] batch [50/281] loss 2.2754 (2.2902) acc 10.9375 (14.0000) lr 1.3090e-03 eta 0:00:16
epoch [4/5] batch [55/281] loss 2.2617 (2.2897) acc 17.1875 (14.1193) lr 1.3090e-03 eta 0:00:15
epoch [4/5] batch [60/281] loss 2.2852 (2.2914) acc 15.6250 (13.8802) lr 1.3090e-03 eta 0:00:15
epoch [4/5] batch [65/281] loss 2.2930 (2.2912) acc 7.8125 (13.8462) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [70/281] loss 2.2637 (2.2907) acc 17.1875 (13.7723) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [75/281] loss 2.3047 (2.2901) acc 9.3750 (13.7708) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [80/281] loss 2.3164 (2.2913) acc 9.3750 (13.5938) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [85/281] loss 2.3223 (2.2910) acc 12.5000 (13.5846) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [90/281] loss 2.3164 (2.2914) acc 10.9375 (13.4722) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [95/281] loss 2.2363 (2.2918) acc 20.3125 (13.4704) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [100/281] loss 2.2773 (2.2915) acc 10.9375 (13.3750) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [105/281] loss 2.3105 (2.2908) acc 6.2500 (13.3631) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [110/281] loss 2.2832 (2.2909) acc 12.5000 (13.2244) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [115/281] loss 2.2871 (2.2909) acc 10.9375 (13.2745) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [120/281] loss 2.3164 (2.2908) acc 14.0625 (13.3203) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [125/281] loss 2.2852 (2.2902) acc 12.5000 (13.4250) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [130/281] loss 2.3164 (2.2905) acc 3.1250 (13.2692) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [135/281] loss 2.3105 (2.2905) acc 10.9375 (13.3565) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [140/281] loss 2.3105 (2.2903) acc 9.3750 (13.4375) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [145/281] loss 2.2773 (2.2906) acc 15.6250 (13.3944) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [150/281] loss 2.2969 (2.2903) acc 14.0625 (13.4688) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [155/281] loss 2.2949 (2.2900) acc 10.9375 (13.5484) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [160/281] loss 2.3125 (2.2898) acc 9.3750 (13.5449) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [165/281] loss 2.3223 (2.2899) acc 12.5000 (13.6080) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [170/281] loss 2.3125 (2.2901) acc 12.5000 (13.5938) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [175/281] loss 2.2812 (2.2899) acc 14.0625 (13.6071) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [180/281] loss 2.3066 (2.2899) acc 7.8125 (13.5851) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [185/281] loss 2.2910 (2.2894) acc 15.6250 (13.6909) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [190/281] loss 2.2656 (2.2894) acc 23.4375 (13.7007) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [195/281] loss 2.2773 (2.2890) acc 20.3125 (13.7821) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [200/281] loss 2.3184 (2.2891) acc 10.9375 (13.7734) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [205/281] loss 2.3516 (2.2892) acc 6.2500 (13.7652) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [210/281] loss 2.2363 (2.2885) acc 17.1875 (13.8170) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [215/281] loss 2.2812 (2.2884) acc 12.5000 (13.8227) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [220/281] loss 2.2930 (2.2885) acc 14.0625 (13.8068) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [225/281] loss 2.2910 (2.2883) acc 12.5000 (13.8542) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [230/281] loss 2.2617 (2.2880) acc 12.5000 (13.8383) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [235/281] loss 2.2539 (2.2881) acc 15.6250 (13.7899) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [240/281] loss 2.2539 (2.2878) acc 21.8750 (13.8411) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [245/281] loss 2.2773 (2.2876) acc 15.6250 (13.8584) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [250/281] loss 2.2793 (2.2873) acc 17.1875 (13.8812) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [255/281] loss 2.2949 (2.2873) acc 10.9375 (13.8664) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [260/281] loss 2.3125 (2.2873) acc 17.1875 (13.8882) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [265/281] loss 2.2793 (2.2874) acc 12.5000 (13.8325) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [270/281] loss 2.3125 (2.2878) acc 14.0625 (13.7963) lr 1.3090e-03 eta 0:00:06
epoch [4/5] batch [275/281] loss 2.2891 (2.2879) acc 10.9375 (13.7386) lr 1.3090e-03 eta 0:00:06
epoch [4/5] batch [280/281] loss 2.2891 (2.2879) acc 9.3750 (13.7165) lr 1.3090e-03 eta 0:00:06
epoch [5/5] batch [5/281] loss 2.3281 (2.2910) acc 6.2500 (10.9375) lr 6.9098e-04 eta 0:00:38
epoch [5/5] batch [10/281] loss 2.2656 (2.2840) acc 14.0625 (10.9375) lr 6.9098e-04 eta 0:00:22
epoch [5/5] batch [15/281] loss 2.2695 (2.2803) acc 14.0625 (11.9792) lr 6.9098e-04 eta 0:00:16
epoch [5/5] batch [20/281] loss 2.3242 (2.2774) acc 14.0625 (13.8281) lr 6.9098e-04 eta 0:00:13
epoch [5/5] batch [25/281] loss 2.3145 (2.2821) acc 6.2500 (12.9375) lr 6.9098e-04 eta 0:00:11
epoch [5/5] batch [30/281] loss 2.2266 (2.2818) acc 20.3125 (13.4375) lr 6.9098e-04 eta 0:00:10
epoch [5/5] batch [35/281] loss 2.2461 (2.2798) acc 18.7500 (13.7500) lr 6.9098e-04 eta 0:00:09
epoch [5/5] batch [40/281] loss 2.2480 (2.2789) acc 12.5000 (13.8281) lr 6.9098e-04 eta 0:00:08
epoch [5/5] batch [45/281] loss 2.2559 (2.2786) acc 18.7500 (13.9583) lr 6.9098e-04 eta 0:00:08
epoch [5/5] batch [50/281] loss 2.2812 (2.2805) acc 14.0625 (13.6250) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [55/281] loss 2.2910 (2.2799) acc 15.6250 (13.7500) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [60/281] loss 2.2578 (2.2793) acc 14.0625 (13.7500) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [65/281] loss 2.3164 (2.2797) acc 7.8125 (13.5337) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [70/281] loss 2.3008 (2.2792) acc 15.6250 (13.4821) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [75/281] loss 2.2754 (2.2796) acc 15.6250 (13.5417) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [80/281] loss 2.2910 (2.2805) acc 10.9375 (13.3594) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [85/281] loss 2.2422 (2.2801) acc 21.8750 (13.4191) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [90/281] loss 2.2715 (2.2801) acc 23.4375 (13.4722) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [95/281] loss 2.2871 (2.2801) acc 17.1875 (13.4375) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [100/281] loss 2.2871 (2.2803) acc 12.5000 (13.4219) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [105/281] loss 2.3145 (2.2812) acc 9.3750 (13.3036) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [110/281] loss 2.2910 (2.2811) acc 9.3750 (13.2102) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [115/281] loss 2.2949 (2.2817) acc 15.6250 (13.2337) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [120/281] loss 2.2656 (2.2816) acc 14.0625 (13.2552) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [125/281] loss 2.2910 (2.2819) acc 10.9375 (13.2625) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [130/281] loss 2.3125 (2.2822) acc 10.9375 (13.3053) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [135/281] loss 2.3047 (2.2823) acc 7.8125 (13.3912) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [140/281] loss 2.2773 (2.2824) acc 18.7500 (13.4710) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [145/281] loss 2.3008 (2.2830) acc 15.6250 (13.4375) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [150/281] loss 2.2930 (2.2832) acc 14.0625 (13.4896) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [155/281] loss 2.3223 (2.2836) acc 7.8125 (13.4173) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [160/281] loss 2.2793 (2.2839) acc 15.6250 (13.4082) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [165/281] loss 2.2715 (2.2841) acc 15.6250 (13.3523) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [170/281] loss 2.2969 (2.2839) acc 12.5000 (13.4926) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [175/281] loss 2.3105 (2.2838) acc 21.8750 (13.5536) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [180/281] loss 2.2734 (2.2838) acc 12.5000 (13.5677) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [185/281] loss 2.3164 (2.2846) acc 6.2500 (13.4628) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [190/281] loss 2.2812 (2.2851) acc 23.4375 (13.4951) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [195/281] loss 2.2949 (2.2851) acc 14.0625 (13.4856) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [200/281] loss 2.3281 (2.2853) acc 7.8125 (13.5000) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [205/281] loss 2.2910 (2.2856) acc 9.3750 (13.5061) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [210/281] loss 2.2676 (2.2857) acc 15.6250 (13.4970) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [215/281] loss 2.3027 (2.2853) acc 15.6250 (13.5538) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [220/281] loss 2.2832 (2.2855) acc 17.1875 (13.5369) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [225/281] loss 2.2793 (2.2857) acc 12.5000 (13.4514) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [230/281] loss 2.2871 (2.2856) acc 15.6250 (13.4918) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [235/281] loss 2.3203 (2.2858) acc 12.5000 (13.4641) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [240/281] loss 2.3086 (2.2861) acc 10.9375 (13.3984) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [245/281] loss 2.3203 (2.2865) acc 10.9375 (13.3482) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [250/281] loss 2.2949 (2.2865) acc 10.9375 (13.3438) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [255/281] loss 2.3027 (2.2866) acc 12.5000 (13.3701) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [260/281] loss 2.2754 (2.2865) acc 14.0625 (13.3834) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [265/281] loss 2.3184 (2.2865) acc 9.3750 (13.3314) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [270/281] loss 2.2734 (2.2863) acc 10.9375 (13.3160) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [275/281] loss 2.2598 (2.2864) acc 10.9375 (13.2898) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [280/281] loss 2.2871 (2.2863) acc 14.0625 (13.2701) lr 6.9098e-04 eta 0:00:00
Model Saved to: output/CLIPAdapter-ViTB32-Digits-mnist/model.pth.tar-5
Finish Training
Evaluate on the Test Set
----------  ------
Total #     6,000
Correct #   1,210
Accuracy    20.17%
Error Rate  79.83%
Macro_F1    14.71%
----------  ------
