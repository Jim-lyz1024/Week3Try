*** Config ***
***************
** Arguments **
***************
dataset: Digits
gpu: 0
model: CLIPAdapter
model_config_file: config/clipadapter.yaml
output_dir: output/CLIPAdapter-ViTB32-Digits-mnist
root: ./data/
seed: 607
source_domains: ['mnist_m', 'svhn', 'syn']
target_domains: ['mnist']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 64
    SAMPLER: RandomSampler
DATASET:
  NAME: Digits
  ROOT: ./data/
  SOURCE_DOMAINS: ['mnist_m', 'svhn', 'syn']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['mnist']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  CLIPAdapter:
    BACKBONE: ViT-B/32
  NAME: CLIPAdapter
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: Cosine
  MAX_EPOCH: 5
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: -1
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/CLIPAdapter-ViTB32-Digits-mnist
SEED: 607
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: CLIPAdapter
Build Dataset: Digits
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  --------------------------
Dataset         Digits
Source Domains  ['mnist_m', 'svhn', 'syn']
Target Domains  ['mnist']
# Classes       10
# Train Data    18,000
# Val Data      3,600
# Test Data     6,000
--------------  --------------------------
Loading CLIP Backbone: ViT-B/32
Building Custom CLIP
Domains:  ['mnist', 'mnist_m', 'svhn', 'syn']
Prompts: ['a picture of a mnist 0.', 'a picture of a mnist 1.', 'a picture of a mnist 2.', 'a picture of a mnist 3.', 'a picture of a mnist 4.', 'a picture of a mnist 5.', 'a picture of a mnist 6.', 'a picture of a mnist 7.', 'a picture of a mnist 8.', 'a picture of a mnist 9.', 'a picture of a mnist_m 0.', 'a picture of a mnist_m 1.', 'a picture of a mnist_m 2.', 'a picture of a mnist_m 3.', 'a picture of a mnist_m 4.', 'a picture of a mnist_m 5.', 'a picture of a mnist_m 6.', 'a picture of a mnist_m 7.', 'a picture of a mnist_m 8.', 'a picture of a mnist_m 9.', 'a picture of a svhn 0.', 'a picture of a svhn 1.', 'a picture of a svhn 2.', 'a picture of a svhn 3.', 'a picture of a svhn 4.', 'a picture of a svhn 5.', 'a picture of a svhn 6.', 'a picture of a svhn 7.', 'a picture of a svhn 8.', 'a picture of a svhn 9.', 'a picture of a syn 0.', 'a picture of a syn 1.', 'a picture of a syn 2.', 'a picture of a syn 3.', 'a picture of a syn 4.', 'a picture of a syn 5.', 'a picture of a syn 6.', 'a picture of a syn 7.', 'a picture of a syn 8.', 'a picture of a syn 9.']
Turning Off Gradients in Image and Text Encoder
Parameters to be updated: {'adapter.fc.2.weight', 'adapter.fc.0.weight'}
Build Evaluator: Classification
epoch [1/5] batch [5/281] loss 3.5176 (3.4461) acc 0.0000 (3.1250) lr 1.0000e-05 eta 0:08:37
epoch [1/5] batch [10/281] loss 3.4648 (3.4828) acc 4.6875 (3.1250) lr 1.0000e-05 eta 0:04:33
epoch [1/5] batch [15/281] loss 3.4434 (3.4983) acc 1.5625 (2.5000) lr 1.0000e-05 eta 0:03:11
epoch [1/5] batch [20/281] loss 3.4121 (3.4866) acc 4.6875 (2.6562) lr 1.0000e-05 eta 0:02:31
epoch [1/5] batch [25/281] loss 3.5039 (3.4863) acc 1.5625 (2.7500) lr 1.0000e-05 eta 0:02:06
epoch [1/5] batch [30/281] loss 3.4336 (3.4882) acc 3.1250 (2.8646) lr 1.0000e-05 eta 0:01:50
epoch [1/5] batch [35/281] loss 3.4434 (3.4853) acc 3.1250 (2.8125) lr 1.0000e-05 eta 0:01:38
epoch [1/5] batch [40/281] loss 3.5410 (3.4932) acc 3.1250 (2.8516) lr 1.0000e-05 eta 0:01:29
epoch [1/5] batch [45/281] loss 3.5391 (3.4963) acc 1.5625 (2.9514) lr 1.0000e-05 eta 0:01:22
epoch [1/5] batch [50/281] loss 3.6172 (3.5049) acc 1.5625 (2.7812) lr 1.0000e-05 eta 0:01:16
epoch [1/5] batch [55/281] loss 3.5137 (3.5024) acc 0.0000 (2.7273) lr 1.0000e-05 eta 0:01:12
epoch [1/5] batch [60/281] loss 3.5684 (3.5045) acc 1.5625 (2.7083) lr 1.0000e-05 eta 0:01:08
epoch [1/5] batch [65/281] loss 3.4668 (3.5047) acc 9.3750 (2.9087) lr 1.0000e-05 eta 0:01:05
epoch [1/5] batch [70/281] loss 3.4414 (3.5076) acc 3.1250 (2.9241) lr 1.0000e-05 eta 0:01:02
epoch [1/5] batch [75/281] loss 3.5410 (3.5068) acc 1.5625 (2.9167) lr 1.0000e-05 eta 0:01:00
epoch [1/5] batch [80/281] loss 3.4961 (3.5049) acc 1.5625 (3.0664) lr 1.0000e-05 eta 0:00:57
epoch [1/5] batch [85/281] loss 3.5059 (3.5060) acc 6.2500 (3.0699) lr 1.0000e-05 eta 0:00:55
epoch [1/5] batch [90/281] loss 3.5254 (3.5079) acc 6.2500 (3.0382) lr 1.0000e-05 eta 0:00:54
epoch [1/5] batch [95/281] loss 3.5156 (3.5080) acc 3.1250 (3.0099) lr 1.0000e-05 eta 0:00:52
epoch [1/5] batch [100/281] loss 3.4395 (3.5085) acc 7.8125 (3.0625) lr 1.0000e-05 eta 0:00:51
epoch [1/5] batch [105/281] loss 3.5098 (3.5072) acc 6.2500 (3.1250) lr 1.0000e-05 eta 0:00:50
epoch [1/5] batch [110/281] loss 3.6016 (3.5092) acc 0.0000 (3.0824) lr 1.0000e-05 eta 0:00:48
epoch [1/5] batch [115/281] loss 3.4824 (3.5092) acc 1.5625 (3.0435) lr 1.0000e-05 eta 0:00:47
epoch [1/5] batch [120/281] loss 3.5332 (3.5074) acc 4.6875 (3.0078) lr 1.0000e-05 eta 0:00:46
epoch [1/5] batch [125/281] loss 3.6074 (3.5070) acc 1.5625 (3.0375) lr 1.0000e-05 eta 0:00:45
epoch [1/5] batch [130/281] loss 3.5742 (3.5068) acc 1.5625 (3.0288) lr 1.0000e-05 eta 0:00:45
epoch [1/5] batch [135/281] loss 3.3926 (3.5066) acc 3.1250 (2.9977) lr 1.0000e-05 eta 0:00:44
epoch [1/5] batch [140/281] loss 3.4688 (3.5073) acc 1.5625 (2.9353) lr 1.0000e-05 eta 0:00:43
epoch [1/5] batch [145/281] loss 3.5664 (3.5075) acc 1.5625 (2.9095) lr 1.0000e-05 eta 0:00:42
epoch [1/5] batch [150/281] loss 3.5527 (3.5091) acc 1.5625 (2.9062) lr 1.0000e-05 eta 0:00:42
epoch [1/5] batch [155/281] loss 3.4922 (3.5085) acc 0.0000 (2.8528) lr 1.0000e-05 eta 0:00:41
epoch [1/5] batch [160/281] loss 3.5762 (3.5097) acc 4.6875 (2.8809) lr 1.0000e-05 eta 0:00:40
epoch [1/5] batch [165/281] loss 3.4941 (3.5086) acc 0.0000 (2.8693) lr 1.0000e-05 eta 0:00:40
epoch [1/5] batch [170/281] loss 3.5742 (3.5083) acc 3.1250 (2.8860) lr 1.0000e-05 eta 0:00:39
epoch [1/5] batch [175/281] loss 3.5918 (3.5078) acc 3.1250 (2.8929) lr 1.0000e-05 eta 0:00:39
epoch [1/5] batch [180/281] loss 3.5820 (3.5083) acc 6.2500 (2.9080) lr 1.0000e-05 eta 0:00:38
epoch [1/5] batch [185/281] loss 3.3496 (3.5071) acc 6.2500 (2.9139) lr 1.0000e-05 eta 0:00:38
epoch [1/5] batch [190/281] loss 3.4805 (3.5062) acc 3.1250 (2.9359) lr 1.0000e-05 eta 0:00:37
epoch [1/5] batch [195/281] loss 3.4453 (3.5062) acc 1.5625 (2.9647) lr 1.0000e-05 eta 0:00:37
epoch [1/5] batch [200/281] loss 3.5137 (3.5062) acc 6.2500 (3.0078) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [205/281] loss 3.4629 (3.5051) acc 1.5625 (2.9954) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [210/281] loss 3.4512 (3.5040) acc 3.1250 (3.0208) lr 1.0000e-05 eta 0:00:36
epoch [1/5] batch [215/281] loss 3.4375 (3.5028) acc 1.5625 (3.0523) lr 1.0000e-05 eta 0:00:35
epoch [1/5] batch [220/281] loss 3.4902 (3.5019) acc 3.1250 (3.1108) lr 1.0000e-05 eta 0:00:35
epoch [1/5] batch [225/281] loss 3.5938 (3.5020) acc 0.0000 (3.0903) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [230/281] loss 3.4277 (3.5019) acc 4.6875 (3.0707) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [235/281] loss 3.4805 (3.5021) acc 3.1250 (3.0984) lr 1.0000e-05 eta 0:00:34
epoch [1/5] batch [240/281] loss 3.4824 (3.5018) acc 3.1250 (3.1055) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [245/281] loss 3.4434 (3.5010) acc 4.6875 (3.0995) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [250/281] loss 3.4883 (3.5003) acc 3.1250 (3.0938) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [255/281] loss 3.4883 (3.4997) acc 4.6875 (3.1066) lr 1.0000e-05 eta 0:00:33
epoch [1/5] batch [260/281] loss 3.3750 (3.4997) acc 4.6875 (3.0889) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [265/281] loss 3.4863 (3.4996) acc 3.1250 (3.0896) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [270/281] loss 3.4902 (3.5000) acc 3.1250 (3.0845) lr 1.0000e-05 eta 0:00:32
epoch [1/5] batch [275/281] loss 3.6016 (3.5003) acc 1.5625 (3.0568) lr 1.0000e-05 eta 0:00:31
epoch [1/5] batch [280/281] loss 3.5137 (3.5003) acc 1.5625 (3.0413) lr 1.0000e-05 eta 0:00:31
epoch [2/5] batch [5/281] loss 3.4375 (3.4570) acc 1.5625 (2.5000) lr 2.0000e-03 eta 0:02:26
epoch [2/5] batch [10/281] loss 3.3711 (3.4377) acc 1.5625 (3.1250) lr 2.0000e-03 eta 0:01:24
epoch [2/5] batch [15/281] loss 3.2793 (3.3882) acc 6.2500 (4.1667) lr 2.0000e-03 eta 0:01:04
epoch [2/5] batch [20/281] loss 3.0996 (3.3313) acc 7.8125 (4.4531) lr 2.0000e-03 eta 0:00:54
epoch [2/5] batch [25/281] loss 2.9414 (3.2805) acc 7.8125 (4.5625) lr 2.0000e-03 eta 0:00:47
epoch [2/5] batch [30/281] loss 2.9180 (3.2264) acc 6.2500 (4.8438) lr 2.0000e-03 eta 0:00:43
epoch [2/5] batch [35/281] loss 2.8457 (3.1775) acc 9.3750 (5.1339) lr 2.0000e-03 eta 0:00:40
epoch [2/5] batch [40/281] loss 2.6973 (3.1250) acc 15.6250 (5.7031) lr 2.0000e-03 eta 0:00:38
epoch [2/5] batch [45/281] loss 2.6445 (3.0751) acc 14.0625 (6.6319) lr 2.0000e-03 eta 0:00:36
epoch [2/5] batch [50/281] loss 2.5645 (3.0289) acc 14.0625 (7.1562) lr 2.0000e-03 eta 0:00:35
epoch [2/5] batch [55/281] loss 2.5762 (2.9832) acc 7.8125 (7.5852) lr 2.0000e-03 eta 0:00:34
epoch [2/5] batch [60/281] loss 2.4629 (2.9407) acc 17.1875 (8.0208) lr 2.0000e-03 eta 0:00:32
epoch [2/5] batch [65/281] loss 2.5039 (2.9023) acc 10.9375 (8.2692) lr 2.0000e-03 eta 0:00:32
epoch [2/5] batch [70/281] loss 2.4082 (2.8693) acc 12.5000 (8.2812) lr 2.0000e-03 eta 0:00:31
epoch [2/5] batch [75/281] loss 2.3965 (2.8393) acc 10.9375 (8.5625) lr 2.0000e-03 eta 0:00:30
epoch [2/5] batch [80/281] loss 2.3906 (2.8107) acc 7.8125 (8.6719) lr 2.0000e-03 eta 0:00:29
epoch [2/5] batch [85/281] loss 2.3633 (2.7864) acc 12.5000 (8.8051) lr 2.0000e-03 eta 0:00:29
epoch [2/5] batch [90/281] loss 2.3516 (2.7620) acc 17.1875 (9.1667) lr 2.0000e-03 eta 0:00:28
epoch [2/5] batch [95/281] loss 2.3945 (2.7410) acc 12.5000 (9.2434) lr 2.0000e-03 eta 0:00:28
epoch [2/5] batch [100/281] loss 2.3652 (2.7208) acc 6.2500 (9.3906) lr 2.0000e-03 eta 0:00:28
epoch [2/5] batch [105/281] loss 2.3477 (2.7033) acc 6.2500 (9.4196) lr 2.0000e-03 eta 0:00:27
epoch [2/5] batch [110/281] loss 2.3262 (2.6885) acc 12.5000 (9.3892) lr 2.0000e-03 eta 0:00:27
epoch [2/5] batch [115/281] loss 2.3184 (2.6740) acc 9.3750 (9.3886) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [120/281] loss 2.3008 (2.6588) acc 10.9375 (9.4661) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [125/281] loss 2.2988 (2.6451) acc 18.7500 (9.6250) lr 2.0000e-03 eta 0:00:26
epoch [2/5] batch [130/281] loss 2.3086 (2.6328) acc 7.8125 (9.7115) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [135/281] loss 2.3027 (2.6214) acc 18.7500 (9.8727) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [140/281] loss 2.3262 (2.6100) acc 12.5000 (10.0558) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [145/281] loss 2.3418 (2.6005) acc 9.3750 (10.0108) lr 2.0000e-03 eta 0:00:25
epoch [2/5] batch [150/281] loss 2.3184 (2.5911) acc 10.9375 (10.0625) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [155/281] loss 2.3066 (2.5825) acc 17.1875 (10.1714) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [160/281] loss 2.3145 (2.5742) acc 18.7500 (10.3223) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [165/281] loss 2.3711 (2.5667) acc 4.6875 (10.3220) lr 2.0000e-03 eta 0:00:24
epoch [2/5] batch [170/281] loss 2.3086 (2.5594) acc 14.0625 (10.3676) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [175/281] loss 2.2988 (2.5523) acc 10.9375 (10.3750) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [180/281] loss 2.3535 (2.5451) acc 6.2500 (10.4340) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [185/281] loss 2.3711 (2.5392) acc 10.9375 (10.4476) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [190/281] loss 2.3398 (2.5334) acc 4.6875 (10.4605) lr 2.0000e-03 eta 0:00:23
epoch [2/5] batch [195/281] loss 2.2949 (2.5276) acc 7.8125 (10.4327) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [200/281] loss 2.3184 (2.5225) acc 7.8125 (10.3672) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [205/281] loss 2.2891 (2.5169) acc 17.1875 (10.4573) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [210/281] loss 2.2578 (2.5116) acc 10.9375 (10.4315) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [215/281] loss 2.2793 (2.5063) acc 6.2500 (10.4869) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [220/281] loss 2.2715 (2.5013) acc 18.7500 (10.5895) lr 2.0000e-03 eta 0:00:22
epoch [2/5] batch [225/281] loss 2.2910 (2.4969) acc 12.5000 (10.5903) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [230/281] loss 2.3359 (2.4927) acc 12.5000 (10.6046) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [235/281] loss 2.3184 (2.4889) acc 9.3750 (10.5918) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [240/281] loss 2.2793 (2.4850) acc 12.5000 (10.5990) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [245/281] loss 2.2812 (2.4815) acc 15.6250 (10.5995) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [250/281] loss 2.2949 (2.4779) acc 12.5000 (10.6188) lr 2.0000e-03 eta 0:00:21
epoch [2/5] batch [255/281] loss 2.3066 (2.4746) acc 6.2500 (10.5453) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [260/281] loss 2.2871 (2.4713) acc 14.0625 (10.5889) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [265/281] loss 2.3008 (2.4679) acc 14.0625 (10.6427) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [270/281] loss 2.2988 (2.4650) acc 12.5000 (10.6655) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [275/281] loss 2.3066 (2.4620) acc 6.2500 (10.6989) lr 2.0000e-03 eta 0:00:20
epoch [2/5] batch [280/281] loss 2.2871 (2.4589) acc 6.2500 (10.7701) lr 2.0000e-03 eta 0:00:20
epoch [3/5] batch [5/281] loss 2.3477 (2.3156) acc 3.1250 (9.3750) lr 1.8090e-03 eta 0:01:49
epoch [3/5] batch [10/281] loss 2.2578 (2.3064) acc 17.1875 (11.0938) lr 1.8090e-03 eta 0:01:03
epoch [3/5] batch [15/281] loss 2.2949 (2.3030) acc 10.9375 (11.9792) lr 1.8090e-03 eta 0:00:48
epoch [3/5] batch [20/281] loss 2.3184 (2.3026) acc 7.8125 (12.0312) lr 1.8090e-03 eta 0:00:40
epoch [3/5] batch [25/281] loss 2.2910 (2.3015) acc 14.0625 (11.8750) lr 1.8090e-03 eta 0:00:35
epoch [3/5] batch [30/281] loss 2.2598 (2.2990) acc 17.1875 (12.1354) lr 1.8090e-03 eta 0:00:32
epoch [3/5] batch [35/281] loss 2.2910 (2.2974) acc 9.3750 (12.1875) lr 1.8090e-03 eta 0:00:30
epoch [3/5] batch [40/281] loss 2.2891 (2.2968) acc 12.5000 (12.1484) lr 1.8090e-03 eta 0:00:28
epoch [3/5] batch [45/281] loss 2.2891 (2.2960) acc 10.9375 (11.9444) lr 1.8090e-03 eta 0:00:27
epoch [3/5] batch [50/281] loss 2.3438 (2.2957) acc 9.3750 (12.0938) lr 1.8090e-03 eta 0:00:26
epoch [3/5] batch [55/281] loss 2.2852 (2.2947) acc 10.9375 (12.1023) lr 1.8090e-03 eta 0:00:25
epoch [3/5] batch [60/281] loss 2.2617 (2.2936) acc 17.1875 (12.3438) lr 1.8090e-03 eta 0:00:24
epoch [3/5] batch [65/281] loss 2.3242 (2.2940) acc 3.1250 (12.3077) lr 1.8090e-03 eta 0:00:23
epoch [3/5] batch [70/281] loss 2.2949 (2.2938) acc 12.5000 (12.4330) lr 1.8090e-03 eta 0:00:22
epoch [3/5] batch [75/281] loss 2.2637 (2.2936) acc 15.6250 (12.5000) lr 1.8090e-03 eta 0:00:22
epoch [3/5] batch [80/281] loss 2.2617 (2.2931) acc 15.6250 (12.3633) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [85/281] loss 2.2988 (2.2943) acc 9.3750 (12.1324) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [90/281] loss 2.2656 (2.2944) acc 14.0625 (12.1181) lr 1.8090e-03 eta 0:00:21
epoch [3/5] batch [95/281] loss 2.3027 (2.2943) acc 9.3750 (12.1217) lr 1.8090e-03 eta 0:00:20
epoch [3/5] batch [100/281] loss 2.3398 (2.2950) acc 6.2500 (12.0312) lr 1.8090e-03 eta 0:00:20
epoch [3/5] batch [105/281] loss 2.2988 (2.2950) acc 12.5000 (12.0982) lr 1.8090e-03 eta 0:00:20
epoch [3/5] batch [110/281] loss 2.2793 (2.2944) acc 12.5000 (12.1591) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [115/281] loss 2.3047 (2.2941) acc 10.9375 (12.1467) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [120/281] loss 2.2715 (2.2940) acc 12.5000 (12.1484) lr 1.8090e-03 eta 0:00:19
epoch [3/5] batch [125/281] loss 2.2969 (2.2940) acc 12.5000 (12.2125) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [130/281] loss 2.2871 (2.2938) acc 9.3750 (12.1995) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [135/281] loss 2.3027 (2.2937) acc 9.3750 (12.2569) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [140/281] loss 2.2656 (2.2929) acc 9.3750 (12.3549) lr 1.8090e-03 eta 0:00:18
epoch [3/5] batch [145/281] loss 2.3125 (2.2933) acc 15.6250 (12.3168) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [150/281] loss 2.3086 (2.2927) acc 15.6250 (12.4896) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [155/281] loss 2.3203 (2.2929) acc 9.3750 (12.4395) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [160/281] loss 2.2520 (2.2925) acc 15.6250 (12.5391) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [165/281] loss 2.3262 (2.2929) acc 7.8125 (12.4527) lr 1.8090e-03 eta 0:00:17
epoch [3/5] batch [170/281] loss 2.2852 (2.2926) acc 12.5000 (12.4816) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [175/281] loss 2.2949 (2.2928) acc 12.5000 (12.4018) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [180/281] loss 2.2676 (2.2925) acc 17.1875 (12.4479) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [185/281] loss 2.2422 (2.2920) acc 23.4375 (12.5507) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [190/281] loss 2.3066 (2.2920) acc 10.9375 (12.5247) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [195/281] loss 2.2910 (2.2919) acc 10.9375 (12.5080) lr 1.8090e-03 eta 0:00:16
epoch [3/5] batch [200/281] loss 2.2988 (2.2922) acc 9.3750 (12.4609) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [205/281] loss 2.3242 (2.2918) acc 7.8125 (12.4924) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [210/281] loss 2.2812 (2.2916) acc 20.3125 (12.5744) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [215/281] loss 2.2578 (2.2916) acc 14.0625 (12.5436) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [220/281] loss 2.2852 (2.2914) acc 18.7500 (12.5923) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [225/281] loss 2.2188 (2.2908) acc 25.0000 (12.7083) lr 1.8090e-03 eta 0:00:15
epoch [3/5] batch [230/281] loss 2.2383 (2.2904) acc 23.4375 (12.7582) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [235/281] loss 2.3125 (2.2904) acc 10.9375 (12.8059) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [240/281] loss 2.2988 (2.2905) acc 7.8125 (12.7604) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [245/281] loss 2.2871 (2.2902) acc 12.5000 (12.7679) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [250/281] loss 2.2852 (2.2900) acc 15.6250 (12.7625) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [255/281] loss 2.2773 (2.2900) acc 9.3750 (12.7512) lr 1.8090e-03 eta 0:00:14
epoch [3/5] batch [260/281] loss 2.2832 (2.2897) acc 12.5000 (12.7584) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [265/281] loss 2.2949 (2.2896) acc 9.3750 (12.7476) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [270/281] loss 2.3027 (2.2893) acc 12.5000 (12.7894) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [275/281] loss 2.2949 (2.2894) acc 15.6250 (12.7727) lr 1.8090e-03 eta 0:00:13
epoch [3/5] batch [280/281] loss 2.2715 (2.2894) acc 18.7500 (12.7623) lr 1.8090e-03 eta 0:00:13
epoch [4/5] batch [5/281] loss 2.3125 (2.2891) acc 9.3750 (10.9375) lr 1.3090e-03 eta 0:01:10
epoch [4/5] batch [10/281] loss 2.3047 (2.2898) acc 7.8125 (10.3125) lr 1.3090e-03 eta 0:00:40
epoch [4/5] batch [15/281] loss 2.2871 (2.2889) acc 12.5000 (11.5625) lr 1.3090e-03 eta 0:00:31
epoch [4/5] batch [20/281] loss 2.2910 (2.2917) acc 17.1875 (11.5625) lr 1.3090e-03 eta 0:00:26
epoch [4/5] batch [25/281] loss 2.3027 (2.2896) acc 4.6875 (11.3750) lr 1.3090e-03 eta 0:00:23
epoch [4/5] batch [30/281] loss 2.2832 (2.2885) acc 23.4375 (12.0833) lr 1.3090e-03 eta 0:00:20
epoch [4/5] batch [35/281] loss 2.2500 (2.2853) acc 21.8750 (12.9018) lr 1.3090e-03 eta 0:00:19
epoch [4/5] batch [40/281] loss 2.2578 (2.2830) acc 17.1875 (13.2422) lr 1.3090e-03 eta 0:00:18
epoch [4/5] batch [45/281] loss 2.2695 (2.2824) acc 17.1875 (13.3681) lr 1.3090e-03 eta 0:00:17
epoch [4/5] batch [50/281] loss 2.2695 (2.2826) acc 14.0625 (13.4062) lr 1.3090e-03 eta 0:00:16
epoch [4/5] batch [55/281] loss 2.2949 (2.2836) acc 15.6250 (13.3239) lr 1.3090e-03 eta 0:00:15
epoch [4/5] batch [60/281] loss 2.2188 (2.2828) acc 21.8750 (13.3073) lr 1.3090e-03 eta 0:00:15
epoch [4/5] batch [65/281] loss 2.2793 (2.2823) acc 14.0625 (13.3413) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [70/281] loss 2.2852 (2.2838) acc 15.6250 (13.2366) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [75/281] loss 2.2812 (2.2829) acc 17.1875 (13.2500) lr 1.3090e-03 eta 0:00:14
epoch [4/5] batch [80/281] loss 2.2988 (2.2832) acc 10.9375 (13.1836) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [85/281] loss 2.2715 (2.2828) acc 18.7500 (13.1985) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [90/281] loss 2.2812 (2.2833) acc 14.0625 (13.0903) lr 1.3090e-03 eta 0:00:13
epoch [4/5] batch [95/281] loss 2.2734 (2.2834) acc 14.0625 (13.0757) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [100/281] loss 2.3047 (2.2839) acc 12.5000 (13.1562) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [105/281] loss 2.3184 (2.2842) acc 10.9375 (13.1399) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [110/281] loss 2.2656 (2.2842) acc 14.0625 (13.1960) lr 1.3090e-03 eta 0:00:12
epoch [4/5] batch [115/281] loss 2.3008 (2.2839) acc 9.3750 (13.2745) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [120/281] loss 2.2910 (2.2838) acc 18.7500 (13.4115) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [125/281] loss 2.2715 (2.2836) acc 17.1875 (13.4125) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [130/281] loss 2.2598 (2.2840) acc 20.3125 (13.3654) lr 1.3090e-03 eta 0:00:11
epoch [4/5] batch [135/281] loss 2.2754 (2.2838) acc 15.6250 (13.3218) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [140/281] loss 2.2734 (2.2839) acc 10.9375 (13.2254) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [145/281] loss 2.3047 (2.2840) acc 12.5000 (13.2435) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [150/281] loss 2.3086 (2.2844) acc 14.0625 (13.1875) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [155/281] loss 2.2500 (2.2842) acc 21.8750 (13.1351) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [160/281] loss 2.2715 (2.2841) acc 15.6250 (13.1152) lr 1.3090e-03 eta 0:00:10
epoch [4/5] batch [165/281] loss 2.2656 (2.2842) acc 18.7500 (13.0398) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [170/281] loss 2.2773 (2.2844) acc 15.6250 (13.0147) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [175/281] loss 2.2949 (2.2846) acc 14.0625 (13.0089) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [180/281] loss 2.2812 (2.2850) acc 7.8125 (12.9774) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [185/281] loss 2.2695 (2.2843) acc 17.1875 (13.0743) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [190/281] loss 2.2480 (2.2841) acc 20.3125 (13.1168) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [195/281] loss 2.3105 (2.2837) acc 7.8125 (13.1571) lr 1.3090e-03 eta 0:00:09
epoch [4/5] batch [200/281] loss 2.3008 (2.2840) acc 12.5000 (13.1172) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [205/281] loss 2.2773 (2.2843) acc 12.5000 (13.0640) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [210/281] loss 2.2930 (2.2844) acc 9.3750 (13.0804) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [215/281] loss 2.2852 (2.2842) acc 17.1875 (13.0887) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [220/281] loss 2.2930 (2.2840) acc 12.5000 (13.1605) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [225/281] loss 2.2988 (2.2842) acc 12.5000 (13.1528) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [230/281] loss 2.2930 (2.2839) acc 15.6250 (13.2065) lr 1.3090e-03 eta 0:00:08
epoch [4/5] batch [235/281] loss 2.2676 (2.2840) acc 20.3125 (13.2513) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [240/281] loss 2.2715 (2.2840) acc 12.5000 (13.2682) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [245/281] loss 2.2773 (2.2841) acc 17.1875 (13.2781) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [250/281] loss 2.2656 (2.2843) acc 15.6250 (13.2500) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [255/281] loss 2.2949 (2.2843) acc 12.5000 (13.2353) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [260/281] loss 2.2363 (2.2841) acc 18.7500 (13.2212) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [265/281] loss 2.2637 (2.2840) acc 14.0625 (13.2193) lr 1.3090e-03 eta 0:00:07
epoch [4/5] batch [270/281] loss 2.2598 (2.2836) acc 17.1875 (13.2465) lr 1.3090e-03 eta 0:00:06
epoch [4/5] batch [275/281] loss 2.2930 (2.2838) acc 9.3750 (13.2386) lr 1.3090e-03 eta 0:00:06
epoch [4/5] batch [280/281] loss 2.2617 (2.2838) acc 10.9375 (13.2143) lr 1.3090e-03 eta 0:00:06
epoch [5/5] batch [5/281] loss 2.3008 (2.2762) acc 4.6875 (13.1250) lr 6.9098e-04 eta 0:00:34
epoch [5/5] batch [10/281] loss 2.3105 (2.2863) acc 9.3750 (13.7500) lr 6.9098e-04 eta 0:00:20
epoch [5/5] batch [15/281] loss 2.2480 (2.2858) acc 15.6250 (12.3958) lr 6.9098e-04 eta 0:00:15
epoch [5/5] batch [20/281] loss 2.2832 (2.2850) acc 7.8125 (11.8750) lr 6.9098e-04 eta 0:00:12
epoch [5/5] batch [25/281] loss 2.2793 (2.2817) acc 10.9375 (12.5000) lr 6.9098e-04 eta 0:00:10
epoch [5/5] batch [30/281] loss 2.2539 (2.2818) acc 12.5000 (12.6042) lr 6.9098e-04 eta 0:00:09
epoch [5/5] batch [35/281] loss 2.2441 (2.2799) acc 20.3125 (12.9464) lr 6.9098e-04 eta 0:00:09
epoch [5/5] batch [40/281] loss 2.3125 (2.2819) acc 9.3750 (12.7344) lr 6.9098e-04 eta 0:00:08
epoch [5/5] batch [45/281] loss 2.2793 (2.2823) acc 18.7500 (12.7778) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [50/281] loss 2.2695 (2.2822) acc 17.1875 (12.7500) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [55/281] loss 2.3184 (2.2833) acc 6.2500 (12.8125) lr 6.9098e-04 eta 0:00:07
epoch [5/5] batch [60/281] loss 2.3145 (2.2837) acc 7.8125 (12.6302) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [65/281] loss 2.2441 (2.2826) acc 17.1875 (12.7885) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [70/281] loss 2.2832 (2.2831) acc 14.0625 (12.7009) lr 6.9098e-04 eta 0:00:06
epoch [5/5] batch [75/281] loss 2.2383 (2.2825) acc 17.1875 (12.6875) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [80/281] loss 2.2344 (2.2823) acc 18.7500 (12.5977) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [85/281] loss 2.2695 (2.2824) acc 12.5000 (12.5551) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [90/281] loss 2.2891 (2.2831) acc 10.9375 (12.5000) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [95/281] loss 2.2793 (2.2824) acc 10.9375 (12.6316) lr 6.9098e-04 eta 0:00:05
epoch [5/5] batch [100/281] loss 2.2617 (2.2821) acc 12.5000 (12.7344) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [105/281] loss 2.2344 (2.2815) acc 17.1875 (12.8571) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [110/281] loss 2.2891 (2.2822) acc 7.8125 (12.7131) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [115/281] loss 2.2773 (2.2820) acc 18.7500 (12.7038) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [120/281] loss 2.2949 (2.2826) acc 9.3750 (12.6562) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [125/281] loss 2.3047 (2.2831) acc 10.9375 (12.5500) lr 6.9098e-04 eta 0:00:04
epoch [5/5] batch [130/281] loss 2.2695 (2.2832) acc 15.6250 (12.5601) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [135/281] loss 2.2910 (2.2834) acc 15.6250 (12.6736) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [140/281] loss 2.2832 (2.2836) acc 14.0625 (12.7679) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [145/281] loss 2.2793 (2.2834) acc 20.3125 (12.7909) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [150/281] loss 2.2715 (2.2837) acc 12.5000 (12.7396) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [155/281] loss 2.2598 (2.2840) acc 15.6250 (12.7218) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [160/281] loss 2.3027 (2.2845) acc 10.9375 (12.5977) lr 6.9098e-04 eta 0:00:03
epoch [5/5] batch [165/281] loss 2.2715 (2.2844) acc 15.6250 (12.5663) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [170/281] loss 2.2422 (2.2839) acc 20.3125 (12.6379) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [175/281] loss 2.2422 (2.2837) acc 23.4375 (12.7232) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [180/281] loss 2.3027 (2.2838) acc 9.3750 (12.6649) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [185/281] loss 2.2734 (2.2837) acc 15.6250 (12.7111) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [190/281] loss 2.2793 (2.2834) acc 12.5000 (12.7385) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [195/281] loss 2.3164 (2.2837) acc 9.3750 (12.7083) lr 6.9098e-04 eta 0:00:02
epoch [5/5] batch [200/281] loss 2.3008 (2.2837) acc 9.3750 (12.7031) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [205/281] loss 2.2969 (2.2839) acc 15.6250 (12.7287) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [210/281] loss 2.2969 (2.2837) acc 7.8125 (12.6786) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [215/281] loss 2.3184 (2.2834) acc 9.3750 (12.7398) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [220/281] loss 2.2617 (2.2832) acc 18.7500 (12.7983) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [225/281] loss 2.2910 (2.2831) acc 12.5000 (12.7847) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [230/281] loss 2.3105 (2.2835) acc 9.3750 (12.7853) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [235/281] loss 2.2891 (2.2837) acc 14.0625 (12.7460) lr 6.9098e-04 eta 0:00:01
epoch [5/5] batch [240/281] loss 2.3008 (2.2841) acc 9.3750 (12.6888) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [245/281] loss 2.2637 (2.2834) acc 12.5000 (12.7105) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [250/281] loss 2.2559 (2.2833) acc 20.3125 (12.7750) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [255/281] loss 2.2793 (2.2832) acc 15.6250 (12.8002) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [260/281] loss 2.2871 (2.2833) acc 9.3750 (12.8065) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [265/281] loss 2.2676 (2.2833) acc 9.3750 (12.8007) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [270/281] loss 2.2871 (2.2832) acc 10.9375 (12.8183) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [275/281] loss 2.2812 (2.2831) acc 12.5000 (12.8182) lr 6.9098e-04 eta 0:00:00
epoch [5/5] batch [280/281] loss 2.2988 (2.2830) acc 12.5000 (12.8237) lr 6.9098e-04 eta 0:00:00
Model Saved to: output/CLIPAdapter-ViTB32-Digits-mnist/model.pth.tar-5
Finish Training
Evaluate on the Test Set
----------  ------
Total #     6,000
Correct #   1,068
Accuracy    17.80%
Error Rate  82.20%
Macro_F1    13.07%
----------  ------
