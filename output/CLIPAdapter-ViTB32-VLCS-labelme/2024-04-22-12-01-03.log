*** Config ***
***************
** Arguments **
***************
dataset: VLCS
gpu: 0
model: CLIPAdapter
model_config_file: config/clipadapter.yaml
output_dir: output/CLIPAdapter-ViTB32-VLCS-labelme
root: ./data/
seed: 134
source_domains: ['caltech', 'pascal', 'sun']
target_domains: ['labelme']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 64
    SAMPLER: RandomSampler
DATASET:
  NAME: VLCS
  ROOT: ./data/
  SOURCE_DOMAINS: ['caltech', 'pascal', 'sun']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['labelme']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  CLIPAdapter:
    BACKBONE: ViT-B/32
  NAME: CLIPAdapter
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: Cosine
  MAX_EPOCH: 2
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: -1
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/CLIPAdapter-ViTB32-VLCS-labelme
SEED: 134
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: CLIPAdapter
Build Dataset: VLCS
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  ----------------------------
Dataset         VLCS
Source Domains  ['caltech', 'pascal', 'sun']
Target Domains  ['labelme']
# Classes       5
# Train Data    5,085
# Val Data      566
# Test Data     797
--------------  ----------------------------
Loading CLIP Backbone: ViT-B/32
Building Custom CLIP
{'original': ['a picture of a bird.', 'a picture of a car.', 'a picture of a chair.', 'a picture of a dog.', 'a picture of a person.'], 'caltech': ['a picture of a caltech bird.', 'a picture of a caltech car.', 'a picture of a caltech chair.', 'a picture of a caltech dog.', 'a picture of a caltech person.'], 'pascal': ['a picture of a pascal bird.', 'a picture of a pascal car.', 'a picture of a pascal chair.', 'a picture of a pascal dog.', 'a picture of a pascal person.'], 'sun': ['a picture of a sun bird.', 'a picture of a sun car.', 'a picture of a sun chair.', 'a picture of a sun dog.', 'a picture of a sun person.']}
Turning Off Gradients in Image and Text Encoder
Parameters to be updated: {'adapter.fc.0.weight', 'adapter.fc.2.weight'}
Build Evaluator: Classification
epoch [1/2] batch [5/79] loss 2.0645 (2.1344) acc 25.0000 (23.1250) lr 1.0000e-05 eta 0:01:17
epoch [1/2] batch [10/79] loss 2.0742 (2.1531) acc 20.3125 (22.5000) lr 1.0000e-05 eta 0:00:38
epoch [1/2] batch [15/79] loss 2.0879 (2.1273) acc 26.5625 (23.1250) lr 1.0000e-05 eta 0:00:25
epoch [1/2] batch [20/79] loss 2.1992 (2.1336) acc 25.0000 (22.8906) lr 1.0000e-05 eta 0:00:18
epoch [1/2] batch [25/79] loss 1.9209 (2.1272) acc 35.9375 (23.3750) lr 1.0000e-05 eta 0:00:14
epoch [1/2] batch [30/79] loss 2.1934 (2.1423) acc 25.0000 (23.2292) lr 1.0000e-05 eta 0:00:12
epoch [1/2] batch [35/79] loss 2.2324 (2.1555) acc 18.7500 (22.8571) lr 1.0000e-05 eta 0:00:10
epoch [1/2] batch [40/79] loss 1.9541 (2.1492) acc 29.6875 (22.7344) lr 1.0000e-05 eta 0:00:09
epoch [1/2] batch [45/79] loss 2.0586 (2.1429) acc 23.4375 (22.7778) lr 1.0000e-05 eta 0:00:07
epoch [1/2] batch [50/79] loss 1.9854 (2.1342) acc 18.7500 (23.0000) lr 1.0000e-05 eta 0:00:07
epoch [1/2] batch [55/79] loss 2.1973 (2.1409) acc 17.1875 (22.9261) lr 1.0000e-05 eta 0:00:06
epoch [1/2] batch [60/79] loss 2.0703 (2.1369) acc 15.6250 (22.8125) lr 1.0000e-05 eta 0:00:05
epoch [1/2] batch [65/79] loss 2.0469 (2.1376) acc 21.8750 (22.6442) lr 1.0000e-05 eta 0:00:05
epoch [1/2] batch [70/79] loss 2.0879 (2.1430) acc 25.0000 (22.4554) lr 1.0000e-05 eta 0:00:04
epoch [1/2] batch [75/79] loss 2.4355 (2.1476) acc 21.8750 (22.3333) lr 1.0000e-05 eta 0:00:04
epoch [2/2] batch [5/79] loss 2.1562 (2.1451) acc 23.4375 (23.4375) lr 2.0000e-03 eta 0:00:17
epoch [2/2] batch [10/79] loss 1.9365 (2.0319) acc 39.0625 (29.2188) lr 2.0000e-03 eta 0:00:08
epoch [2/2] batch [15/79] loss 1.6738 (1.9405) acc 37.5000 (31.4583) lr 2.0000e-03 eta 0:00:05
epoch [2/2] batch [20/79] loss 1.6123 (1.8436) acc 43.7500 (34.7656) lr 2.0000e-03 eta 0:00:04
epoch [2/2] batch [25/79] loss 1.6738 (1.7790) acc 46.8750 (37.7500) lr 2.0000e-03 eta 0:00:03
epoch [2/2] batch [30/79] loss 1.0605 (1.6957) acc 60.9375 (41.0417) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [35/79] loss 0.8735 (1.6119) acc 71.8750 (44.7321) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [40/79] loss 0.9082 (1.5239) acc 70.3125 (48.2422) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [45/79] loss 0.8550 (1.4534) acc 75.0000 (51.1806) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [50/79] loss 0.7925 (1.3976) acc 75.0000 (52.9375) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [55/79] loss 0.5674 (1.3346) acc 84.3750 (55.2557) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [60/79] loss 0.6743 (1.2838) acc 79.6875 (57.0052) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [65/79] loss 0.6733 (1.2393) acc 81.2500 (58.4135) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [70/79] loss 0.5186 (1.1966) acc 82.8125 (59.8884) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [75/79] loss 0.7456 (1.1650) acc 68.7500 (60.7500) lr 2.0000e-03 eta 0:00:00
Model Saved to: output/CLIPAdapter-ViTB32-VLCS-labelme/model.pth.tar-2
Finish Training
Evaluate on the Test Set
{'original': ['a picture of a bird.', 'a picture of a car.', 'a picture of a chair.', 'a picture of a dog.', 'a picture of a person.'], 'labelme': ['a picture of a labelme bird.', 'a picture of a labelme car.', 'a picture of a labelme chair.', 'a picture of a labelme dog.', 'a picture of a labelme person.']}
{'original': tensor([[ 0.0262,  0.0139, -0.0079,  ..., -0.0453,  0.0063, -0.0239],
        [ 0.0127,  0.0005, -0.0154,  ..., -0.0260, -0.0305,  0.0026],
        [-0.0192, -0.0017, -0.0054,  ..., -0.0481, -0.0271,  0.0161],
        [ 0.0130,  0.0088, -0.0393,  ..., -0.0427, -0.0132,  0.0195],
        [ 0.0049,  0.0079, -0.0011,  ..., -0.0593, -0.0150, -0.0024]],
       device='cuda:0', dtype=torch.float16), 'labelme': tensor([[ 0.0263,  0.0403,  0.0055,  ..., -0.0259,  0.0183, -0.0487],
        [ 0.0159,  0.0213,  0.0028,  ..., -0.0227, -0.0081, -0.0183],
        [-0.0203,  0.0262,  0.0291,  ..., -0.0357, -0.0021, -0.0067],
        [ 0.0112,  0.0233, -0.0202,  ..., -0.0282,  0.0006,  0.0045],
        [ 0.0067,  0.0134,  0.0117,  ..., -0.0307,  0.0112, -0.0201]],
       device='cuda:0', dtype=torch.float16)}
----------  ------
Total #     797
Correct #   509
Accuracy    63.86%
Error Rate  36.14%
Macro_F1    61.58%
----------  ------
