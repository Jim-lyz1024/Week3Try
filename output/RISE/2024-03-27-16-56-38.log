*** Config ***
***************
** Arguments **
***************
dataset: PACS
gpu: 0
model: RISE
model_config_file: config/rise.yaml
output_dir: output/RISE
root: ./data/
seed: 42
source_domains: ['cartoon', 'photo', 'sketch']
target_domains: ['art_painting']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 128
    SAMPLER: RandomSampler
DATASET:
  NAME: PACS
  ROOT: ./data/
  SOURCE_DOMAINS: ['cartoon', 'photo', 'sketch']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['art_painting']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  NAME: RISE
  RISE:
    BACKBONE: ViT-B/32
    LOSS_WEIGHT:
      CLASSIFICATION: 0.1
      DISTANCE: 0.5
      DISTILLATION: 0.9
    STUDENT_NETWORK: resnet18
    TEMPERATURE: 3.0
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.001
  LR_SCHEDULER: StepLR
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: 16
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: none
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/RISE
SEED: 42
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: RISE
Build Dataset: PACS
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  ------------------------------
Dataset         PACS
Source Domains  ['cartoon', 'photo', 'sketch']
Target Domains  ['art_painting']
# Classes       7
# Train Data    7,942
# Val Data      806
# Test Data     2,048
--------------  ------------------------------
Loading CLIP Backbone: ViT-B/32
Distillation_Loss_Weight: 0.9
Classification_Loss_Weight: 0.1
Distance Loss Weight: 0.5
Temperature: 3.0
Build Evaluator: Classification
epoch [1/50] batch [5/62] loss 4.7494 (4.7504) distil_loss 4.5251 (4.5276) class_loss 1.9654 (1.9575) absolute_loss 0.9585 (0.9575) relative_loss 0.0021 (0.0021) acc 11.7188 (13.9062) lr 1.0000e-03 eta 0:43:16
epoch [1/50] batch [10/62] loss 4.7446 (4.7225) distil_loss 4.5213 (4.4973) class_loss 1.9507 (1.9549) absolute_loss 0.9586 (0.9569) relative_loss 0.0021 (0.0021) acc 14.0625 (14.7656) lr 1.0000e-03 eta 0:28:39
epoch [1/50] batch [15/62] loss 4.3882 (4.6972) distil_loss 4.1252 (4.4697) class_loss 1.9498 (1.9498) absolute_loss 0.9588 (0.9569) relative_loss 0.0022 (0.0021) acc 10.9375 (14.3229) lr 1.0000e-03 eta 0:23:46
epoch [1/50] batch [20/62] loss 4.2246 (4.6219) distil_loss 3.9508 (4.3873) class_loss 1.8912 (1.9380) absolute_loss 0.9575 (0.9568) relative_loss 0.0021 (0.0021) acc 14.8438 (14.7656) lr 1.0000e-03 eta 0:21:19
epoch [1/50] batch [25/62] loss 4.2838 (4.5713) distil_loss 4.0168 (4.3315) class_loss 1.8889 (1.9344) absolute_loss 0.9576 (0.9568) relative_loss 0.0021 (0.0021) acc 17.1875 (15.0000) lr 1.0000e-03 eta 0:19:50
epoch [1/50] batch [30/62] loss 4.2128 (4.5331) distil_loss 3.9440 (4.2902) class_loss 1.8405 (1.9247) absolute_loss 0.9561 (0.9567) relative_loss 0.0022 (0.0021) acc 17.9688 (15.5990) lr 1.0000e-03 eta 0:18:50
epoch [1/50] batch [35/62] loss 4.3186 (4.5263) distil_loss 4.0466 (4.2825) class_loss 1.9586 (1.9248) absolute_loss 0.9594 (0.9570) relative_loss 0.0022 (0.0021) acc 12.5000 (15.7143) lr 1.0000e-03 eta 0:18:07
epoch [1/50] batch [40/62] loss 4.4851 (4.4933) distil_loss 4.2477 (4.2460) class_loss 1.8316 (1.9238) absolute_loss 0.9559 (0.9569) relative_loss 0.0022 (0.0021) acc 19.5312 (15.7812) lr 1.0000e-03 eta 0:17:35
epoch [1/50] batch [45/62] loss 4.6383 (4.4766) distil_loss 4.4082 (4.2280) class_loss 1.9244 (1.9189) absolute_loss 0.9549 (0.9569) relative_loss 0.0021 (0.0021) acc 15.6250 (16.0764) lr 1.0000e-03 eta 0:17:09
epoch [1/50] batch [50/62] loss 4.6789 (4.4737) distil_loss 4.4622 (4.2250) class_loss 1.8351 (1.9166) absolute_loss 0.9568 (0.9569) relative_loss 0.0021 (0.0021) acc 21.8750 (16.2812) lr 1.0000e-03 eta 0:16:48
epoch [1/50] batch [55/62] loss 4.5729 (4.4800) distil_loss 4.3348 (4.2322) class_loss 1.9220 (1.9149) absolute_loss 0.9566 (0.9570) relative_loss 0.0021 (0.0021) acc 18.7500 (16.4915) lr 1.0000e-03 eta 0:16:30
epoch [1/50] batch [60/62] loss 4.3540 (4.4554) distil_loss 4.1014 (4.2053) class_loss 1.8322 (1.9107) absolute_loss 0.9569 (0.9569) relative_loss 0.0021 (0.0021) acc 23.4375 (16.7318) lr 1.0000e-03 eta 0:16:14
epoch [2/50] batch [5/62] loss 3.6766 (3.8907) distil_loss 3.3564 (3.5897) class_loss 1.7651 (1.8050) absolute_loss 0.9565 (0.9568) relative_loss 0.0021 (0.0021) acc 25.7812 (24.2188) lr 1.0000e-03 eta 0:23:21
epoch [2/50] batch [10/62] loss 3.5864 (3.9981) distil_loss 3.2505 (3.7078) class_loss 1.8222 (1.8171) absolute_loss 0.9554 (0.9566) relative_loss 0.0022 (0.0021) acc 23.4375 (23.9844) lr 1.0000e-03 eta 0:18:41
epoch [2/50] batch [15/62] loss 3.9477 (3.9447) distil_loss 3.6544 (3.6484) class_loss 1.7964 (1.8174) absolute_loss 0.9560 (0.9568) relative_loss 0.0021 (0.0021) acc 28.1250 (24.7917) lr 1.0000e-03 eta 0:17:06
epoch [2/50] batch [20/62] loss 3.7738 (3.9985) distil_loss 3.4626 (3.7073) class_loss 1.7652 (1.8246) absolute_loss 0.9596 (0.9569) relative_loss 0.0022 (0.0021) acc 31.2500 (25.3125) lr 1.0000e-03 eta 0:16:19
epoch [2/50] batch [25/62] loss 3.9742 (4.0099) distil_loss 3.6858 (3.7202) class_loss 1.7793 (1.8221) absolute_loss 0.9561 (0.9568) relative_loss 0.0022 (0.0021) acc 23.4375 (25.3750) lr 1.0000e-03 eta 0:15:49
epoch [2/50] batch [30/62] loss 4.2788 (4.0118) distil_loss 4.0264 (3.7234) class_loss 1.7559 (1.8135) absolute_loss 0.9567 (0.9567) relative_loss 0.0021 (0.0021) acc 26.5625 (25.4948) lr 1.0000e-03 eta 0:15:29
epoch [2/50] batch [35/62] loss 3.8836 (4.0301) distil_loss 3.5908 (3.7443) class_loss 1.7194 (1.8078) absolute_loss 0.9577 (0.9567) relative_loss 0.0021 (0.0021) acc 28.9062 (25.9598) lr 1.0000e-03 eta 0:15:15
epoch [2/50] batch [40/62] loss 4.1786 (4.0564) distil_loss 3.9066 (3.7737) class_loss 1.8284 (1.8049) absolute_loss 0.9573 (0.9569) relative_loss 0.0022 (0.0021) acc 24.2188 (26.2305) lr 1.0000e-03 eta 0:15:03
