*** Config ***
***************
** Arguments **
***************
dataset: PACS
gpu: 0
model: CLIPAdapter
model_config_file: config/clipadapter.yaml
output_dir: output/CLIPAdapter-ViTB32-PACS-art_painting
root: ./data/
seed: 134
source_domains: ['cartoon', 'photo', 'sketch']
target_domains: ['art_painting']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 64
    SAMPLER: RandomSampler
DATASET:
  NAME: PACS
  ROOT: ./data/
  SOURCE_DOMAINS: ['cartoon', 'photo', 'sketch']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['art_painting']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  CLIPAdapter:
    BACKBONE: ViT-B/32
  NAME: CLIPAdapter
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: Cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: -1
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/CLIPAdapter-ViTB32-PACS-art_painting
SEED: 134
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: CLIPAdapter
Build Dataset: PACS
File Extracted to E:\Documents\GitHub\Week3Try\data
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  ------------------------------
Dataset         PACS
Source Domains  ['cartoon', 'photo', 'sketch']
Target Domains  ['art_painting']
# Classes       7
# Train Data    7,942
# Val Data      806
# Test Data     2,048
--------------  ------------------------------
Loading CLIP Backbone: ViT-B/32
Building Custom CLIP
Turning Off Gradients in Image and Text Encoder
Parameters to be updated: {'adapter.fc.0.weight', 'adapter.fc.2.weight'}
Build Evaluator: Classification
epoch [1/50] batch [5/124] loss 0.3989 (0.5194) acc 85.9375 (80.3125) lr 1.0000e-05 eta 11:18:38
epoch [1/50] batch [10/124] loss 0.6704 (0.5508) acc 75.0000 (78.2812) lr 1.0000e-05 eta 5:43:23
epoch [1/50] batch [15/124] loss 0.6685 (0.5171) acc 73.4375 (79.7917) lr 1.0000e-05 eta 3:51:33
epoch [1/50] batch [20/124] loss 0.3240 (0.5061) acc 87.5000 (80.3125) lr 1.0000e-05 eta 2:55:37
epoch [1/50] batch [25/124] loss 0.4880 (0.5136) acc 84.3750 (80.1875) lr 1.0000e-05 eta 2:22:04
epoch [1/50] batch [30/124] loss 0.5366 (0.5063) acc 79.6875 (80.7812) lr 1.0000e-05 eta 1:59:43
epoch [1/50] batch [35/124] loss 0.4597 (0.5019) acc 82.8125 (81.0714) lr 1.0000e-05 eta 1:43:47
epoch [1/50] batch [40/124] loss 0.4634 (0.4953) acc 75.0000 (81.1719) lr 1.0000e-05 eta 1:31:50
epoch [1/50] batch [45/124] loss 0.4065 (0.4885) acc 84.3750 (81.3542) lr 1.0000e-05 eta 1:22:30
epoch [1/50] batch [50/124] loss 0.4761 (0.4913) acc 84.3750 (81.4688) lr 1.0000e-05 eta 1:15:01
epoch [1/50] batch [55/124] loss 0.5815 (0.5015) acc 78.1250 (81.1364) lr 1.0000e-05 eta 1:08:54
epoch [1/50] batch [60/124] loss 0.2336 (0.4938) acc 93.7500 (81.4844) lr 1.0000e-05 eta 1:03:48
epoch [1/50] batch [65/124] loss 0.5103 (0.5020) acc 82.8125 (81.1538) lr 1.0000e-05 eta 0:59:29
epoch [1/50] batch [70/124] loss 0.7021 (0.5111) acc 76.5625 (80.7812) lr 1.0000e-05 eta 0:55:47
epoch [1/50] batch [75/124] loss 0.4717 (0.5129) acc 84.3750 (80.7708) lr 1.0000e-05 eta 0:52:34
epoch [1/50] batch [80/124] loss 0.4912 (0.5141) acc 82.8125 (80.7031) lr 1.0000e-05 eta 0:49:45
epoch [1/50] batch [85/124] loss 0.4280 (0.5135) acc 85.9375 (80.7537) lr 1.0000e-05 eta 0:47:16
epoch [1/50] batch [90/124] loss 0.3206 (0.5126) acc 89.0625 (80.7465) lr 1.0000e-05 eta 0:45:03
epoch [1/50] batch [95/124] loss 0.3831 (0.5104) acc 87.5000 (80.8388) lr 1.0000e-05 eta 0:43:05
epoch [1/50] batch [100/124] loss 0.5522 (0.5121) acc 75.0000 (80.7500) lr 1.0000e-05 eta 0:41:18
epoch [1/50] batch [105/124] loss 0.5688 (0.5139) acc 81.2500 (80.6845) lr 1.0000e-05 eta 0:39:41
epoch [1/50] batch [110/124] loss 0.4868 (0.5144) acc 82.8125 (80.7528) lr 1.0000e-05 eta 0:38:13
epoch [1/50] batch [115/124] loss 0.5405 (0.5149) acc 81.2500 (80.8152) lr 1.0000e-05 eta 0:36:53
epoch [1/50] batch [120/124] loss 0.6914 (0.5113) acc 71.8750 (80.9115) lr 1.0000e-05 eta 0:35:39
epoch [2/50] batch [5/124] loss 0.4763 (0.5634) acc 76.5625 (77.5000) lr 2.0000e-03 eta 10:29:51
epoch [2/50] batch [10/124] loss 0.5957 (0.5139) acc 82.8125 (80.7812) lr 2.0000e-03 eta 5:18:50
epoch [2/50] batch [15/124] loss 0.5303 (0.5176) acc 82.8125 (80.6250) lr 2.0000e-03 eta 3:35:02
epoch [2/50] batch [20/124] loss 0.5620 (0.5108) acc 81.2500 (81.0156) lr 2.0000e-03 eta 2:43:06
epoch [2/50] batch [25/124] loss 0.4824 (0.5073) acc 79.6875 (80.8750) lr 2.0000e-03 eta 2:11:56
epoch [2/50] batch [30/124] loss 0.4885 (0.5138) acc 84.3750 (81.0938) lr 2.0000e-03 eta 1:51:09
epoch [2/50] batch [35/124] loss 0.6553 (0.5148) acc 76.5625 (80.9821) lr 2.0000e-03 eta 1:36:19
epoch [2/50] batch [40/124] loss 0.3650 (0.5014) acc 84.3750 (81.3672) lr 2.0000e-03 eta 1:25:11
epoch [2/50] batch [45/124] loss 0.5000 (0.5017) acc 81.2500 (81.4931) lr 2.0000e-03 eta 1:16:31
epoch [2/50] batch [50/124] loss 0.4487 (0.5099) acc 79.6875 (81.1562) lr 2.0000e-03 eta 1:09:36
epoch [2/50] batch [55/124] loss 0.5664 (0.5080) acc 76.5625 (81.3636) lr 2.0000e-03 eta 1:03:55
epoch [2/50] batch [60/124] loss 0.5659 (0.5090) acc 73.4375 (81.1198) lr 2.0000e-03 eta 0:59:11
epoch [2/50] batch [65/124] loss 0.3945 (0.5111) acc 85.9375 (80.9375) lr 2.0000e-03 eta 0:55:11
epoch [2/50] batch [70/124] loss 0.6045 (0.5150) acc 82.8125 (80.9152) lr 2.0000e-03 eta 0:51:45
epoch [2/50] batch [75/124] loss 0.6260 (0.5165) acc 73.4375 (80.7708) lr 2.0000e-03 eta 0:48:46
epoch [2/50] batch [80/124] loss 0.4829 (0.5185) acc 84.3750 (80.7227) lr 2.0000e-03 eta 0:46:10
epoch [2/50] batch [85/124] loss 0.5669 (0.5202) acc 82.8125 (80.6618) lr 2.0000e-03 eta 0:43:52
epoch [2/50] batch [90/124] loss 0.2605 (0.5139) acc 90.6250 (81.0069) lr 2.0000e-03 eta 0:41:49
epoch [2/50] batch [95/124] loss 0.4172 (0.5141) acc 84.3750 (81.0362) lr 2.0000e-03 eta 0:39:59
epoch [2/50] batch [100/124] loss 0.3738 (0.5137) acc 85.9375 (81.0625) lr 2.0000e-03 eta 0:38:20
epoch [2/50] batch [105/124] loss 0.5156 (0.5145) acc 82.8125 (81.0119) lr 2.0000e-03 eta 0:36:50
epoch [2/50] batch [110/124] loss 0.3140 (0.5116) acc 89.0625 (81.0653) lr 2.0000e-03 eta 0:35:28
epoch [2/50] batch [115/124] loss 0.5200 (0.5103) acc 79.6875 (81.1005) lr 2.0000e-03 eta 0:34:13
epoch [2/50] batch [120/124] loss 0.5205 (0.5110) acc 85.9375 (81.1068) lr 2.0000e-03 eta 0:33:05
epoch [3/50] batch [5/124] loss 0.2913 (0.5209) acc 89.0625 (80.9375) lr 1.9980e-03 eta 10:12:14
epoch [3/50] batch [10/124] loss 0.3818 (0.4737) acc 87.5000 (82.8125) lr 1.9980e-03 eta 5:09:40
epoch [3/50] batch [15/124] loss 0.5337 (0.4737) acc 79.6875 (82.7083) lr 1.9980e-03 eta 3:28:49
epoch [3/50] batch [20/124] loss 0.3933 (0.4603) acc 85.9375 (83.1250) lr 1.9980e-03 eta 2:38:23
epoch [3/50] batch [25/124] loss 0.5371 (0.4783) acc 84.3750 (82.3750) lr 1.9980e-03 eta 2:08:08
epoch [3/50] batch [30/124] loss 0.3840 (0.4692) acc 89.0625 (83.0729) lr 1.9980e-03 eta 1:47:58
epoch [3/50] batch [35/124] loss 0.6211 (0.4751) acc 84.3750 (83.1696) lr 1.9980e-03 eta 1:33:34
epoch [3/50] batch [40/124] loss 0.5435 (0.4747) acc 79.6875 (82.9688) lr 1.9980e-03 eta 1:22:45
epoch [3/50] batch [45/124] loss 0.5298 (0.4777) acc 79.6875 (82.9167) lr 1.9980e-03 eta 1:14:20
epoch [3/50] batch [50/124] loss 0.3904 (0.4812) acc 85.9375 (82.8750) lr 1.9980e-03 eta 1:07:36
epoch [3/50] batch [55/124] loss 0.7646 (0.4847) acc 67.1875 (82.6989) lr 1.9980e-03 eta 1:02:04
epoch [3/50] batch [60/124] loss 0.4531 (0.4840) acc 81.2500 (82.6562) lr 1.9980e-03 eta 0:57:28
epoch [3/50] batch [65/124] loss 0.4126 (0.4853) acc 89.0625 (82.6683) lr 1.9980e-03 eta 0:53:35
epoch [3/50] batch [70/124] loss 0.3857 (0.4832) acc 87.5000 (82.7679) lr 1.9980e-03 eta 0:50:14
epoch [3/50] batch [75/124] loss 0.4480 (0.4795) acc 85.9375 (82.9167) lr 1.9980e-03 eta 0:47:21
epoch [3/50] batch [80/124] loss 0.6934 (0.4781) acc 71.8750 (82.8906) lr 1.9980e-03 eta 0:44:49
epoch [3/50] batch [85/124] loss 0.4819 (0.4814) acc 81.2500 (82.5919) lr 1.9980e-03 eta 0:42:34
epoch [3/50] batch [90/124] loss 0.4856 (0.4775) acc 76.5625 (82.7257) lr 1.9980e-03 eta 0:40:35
epoch [3/50] batch [95/124] loss 0.4436 (0.4758) acc 81.2500 (82.5987) lr 1.9980e-03 eta 0:38:48
epoch [3/50] batch [100/124] loss 0.3513 (0.4750) acc 85.9375 (82.6406) lr 1.9980e-03 eta 0:37:12
epoch [3/50] batch [105/124] loss 0.4844 (0.4778) acc 78.1250 (82.4702) lr 1.9980e-03 eta 0:35:44
epoch [3/50] batch [110/124] loss 0.7026 (0.4810) acc 73.4375 (82.3438) lr 1.9980e-03 eta 0:34:25
epoch [3/50] batch [115/124] loss 0.4758 (0.4809) acc 87.5000 (82.3777) lr 1.9980e-03 eta 0:33:13
epoch [3/50] batch [120/124] loss 0.4622 (0.4810) acc 84.3750 (82.4089) lr 1.9980e-03 eta 0:32:06
epoch [4/50] batch [5/124] loss 0.4944 (0.5343) acc 76.5625 (80.6250) lr 1.9921e-03 eta 9:55:24
epoch [4/50] batch [10/124] loss 0.4036 (0.4801) acc 90.6250 (82.6562) lr 1.9921e-03 eta 5:01:10
epoch [4/50] batch [15/124] loss 0.4434 (0.4662) acc 79.6875 (83.6458) lr 1.9921e-03 eta 3:23:07
epoch [4/50] batch [20/124] loss 0.5854 (0.4840) acc 76.5625 (82.9688) lr 1.9921e-03 eta 2:34:06
epoch [4/50] batch [25/124] loss 0.3857 (0.4773) acc 85.9375 (82.8125) lr 1.9921e-03 eta 2:04:41
epoch [4/50] batch [30/124] loss 0.4514 (0.4756) acc 79.6875 (82.8125) lr 1.9921e-03 eta 1:45:03
epoch [4/50] batch [35/124] loss 0.5503 (0.4730) acc 81.2500 (82.8571) lr 1.9921e-03 eta 1:31:01
epoch [4/50] batch [40/124] loss 0.4956 (0.4842) acc 84.3750 (82.4219) lr 1.9921e-03 eta 1:20:29
epoch [4/50] batch [45/124] loss 0.5063 (0.4907) acc 78.1250 (82.0833) lr 1.9921e-03 eta 1:12:18
epoch [4/50] batch [50/124] loss 0.5386 (0.4872) acc 81.2500 (82.2500) lr 1.9921e-03 eta 1:05:45
epoch [4/50] batch [55/124] loss 0.5791 (0.4902) acc 76.5625 (82.1023) lr 1.9921e-03 eta 1:00:23
epoch [4/50] batch [60/124] loss 0.7681 (0.4911) acc 71.8750 (82.0573) lr 1.9921e-03 eta 0:55:54
epoch [4/50] batch [65/124] loss 0.5386 (0.4977) acc 81.2500 (81.7788) lr 1.9921e-03 eta 0:52:07
epoch [4/50] batch [70/124] loss 0.4197 (0.4919) acc 85.9375 (82.1205) lr 1.9921e-03 eta 0:48:52
epoch [4/50] batch [75/124] loss 0.5229 (0.4922) acc 76.5625 (82.0208) lr 1.9921e-03 eta 0:46:03
epoch [4/50] batch [80/124] loss 0.5693 (0.4910) acc 75.0000 (81.9727) lr 1.9921e-03 eta 0:43:36
epoch [4/50] batch [85/124] loss 0.5640 (0.4945) acc 76.5625 (81.7831) lr 1.9921e-03 eta 0:41:25
epoch [4/50] batch [90/124] loss 0.6572 (0.4936) acc 73.4375 (81.8056) lr 1.9921e-03 eta 0:39:29
epoch [4/50] batch [95/124] loss 0.3560 (0.4932) acc 90.6250 (81.8914) lr 1.9921e-03 eta 0:37:45
epoch [4/50] batch [100/124] loss 0.3940 (0.4898) acc 79.6875 (82.0938) lr 1.9921e-03 eta 0:36:12
epoch [4/50] batch [105/124] loss 0.5522 (0.4934) acc 81.2500 (82.0387) lr 1.9921e-03 eta 0:34:47
epoch [4/50] batch [110/124] loss 0.4866 (0.4945) acc 87.5000 (82.0028) lr 1.9921e-03 eta 0:33:30
epoch [4/50] batch [115/124] loss 0.4888 (0.4937) acc 76.5625 (81.9565) lr 1.9921e-03 eta 0:32:20
epoch [4/50] batch [120/124] loss 0.5068 (0.4909) acc 81.2500 (82.1224) lr 1.9921e-03 eta 0:31:15
epoch [5/50] batch [5/124] loss 0.5264 (0.5448) acc 76.5625 (78.4375) lr 1.9823e-03 eta 10:00:53
epoch [5/50] batch [10/124] loss 0.4048 (0.5045) acc 85.9375 (81.2500) lr 1.9823e-03 eta 5:03:49
epoch [5/50] batch [15/124] loss 0.6011 (0.5130) acc 78.1250 (81.3542) lr 1.9823e-03 eta 3:24:48
epoch [5/50] batch [20/124] loss 0.4829 (0.5038) acc 85.9375 (81.7969) lr 1.9823e-03 eta 2:35:17
epoch [5/50] batch [25/124] loss 0.4355 (0.5142) acc 85.9375 (81.3750) lr 1.9823e-03 eta 2:05:34
epoch [5/50] batch [30/124] loss 0.4941 (0.5066) acc 82.8125 (81.5104) lr 1.9823e-03 eta 1:45:47
epoch [5/50] batch [35/124] loss 0.3916 (0.4931) acc 87.5000 (81.8750) lr 1.9823e-03 eta 1:31:38
epoch [5/50] batch [40/124] loss 0.4336 (0.4930) acc 84.3750 (81.8750) lr 1.9823e-03 eta 1:21:02
epoch [5/50] batch [45/124] loss 0.6943 (0.4985) acc 73.4375 (81.5278) lr 1.9823e-03 eta 1:12:47
epoch [5/50] batch [50/124] loss 0.2275 (0.4890) acc 92.1875 (81.9062) lr 1.9823e-03 eta 1:06:11
epoch [5/50] batch [55/124] loss 0.4236 (0.4890) acc 90.6250 (81.9886) lr 1.9823e-03 eta 1:00:46
epoch [5/50] batch [60/124] loss 0.5122 (0.4812) acc 82.8125 (82.2917) lr 1.9823e-03 eta 0:56:16
epoch [5/50] batch [65/124] loss 0.3318 (0.4781) acc 85.9375 (82.3798) lr 1.9823e-03 eta 0:52:27
epoch [5/50] batch [70/124] loss 0.3276 (0.4738) acc 90.6250 (82.6116) lr 1.9823e-03 eta 0:49:10
epoch [5/50] batch [75/124] loss 0.4189 (0.4716) acc 89.0625 (82.7500) lr 1.9823e-03 eta 0:46:20
epoch [5/50] batch [80/124] loss 0.5967 (0.4723) acc 79.6875 (82.7539) lr 1.9823e-03 eta 0:43:50
epoch [5/50] batch [85/124] loss 0.2710 (0.4669) acc 92.1875 (82.9228) lr 1.9823e-03 eta 0:41:39
epoch [5/50] batch [90/124] loss 0.4297 (0.4670) acc 81.2500 (82.8125) lr 1.9823e-03 eta 0:39:41
epoch [5/50] batch [95/124] loss 0.4583 (0.4647) acc 82.8125 (82.9934) lr 1.9823e-03 eta 0:37:57
epoch [5/50] batch [100/124] loss 0.3696 (0.4622) acc 87.5000 (83.0469) lr 1.9823e-03 eta 0:36:22
epoch [5/50] batch [105/124] loss 0.5679 (0.4625) acc 79.6875 (83.1250) lr 1.9823e-03 eta 0:34:57
epoch [5/50] batch [110/124] loss 0.4871 (0.4651) acc 85.9375 (83.1392) lr 1.9823e-03 eta 0:33:39
epoch [5/50] batch [115/124] loss 0.4983 (0.4649) acc 79.6875 (83.1386) lr 1.9823e-03 eta 0:32:28
epoch [5/50] batch [120/124] loss 0.6426 (0.4667) acc 75.0000 (83.1120) lr 1.9823e-03 eta 0:31:22
epoch [6/50] batch [5/124] loss 0.5132 (0.4479) acc 79.6875 (82.8125) lr 1.9686e-03 eta 9:35:41
epoch [6/50] batch [10/124] loss 0.4124 (0.4418) acc 84.3750 (83.5938) lr 1.9686e-03 eta 4:51:10
epoch [6/50] batch [15/124] loss 0.4802 (0.4573) acc 81.2500 (83.0208) lr 1.9686e-03 eta 3:16:22
epoch [6/50] batch [20/124] loss 0.4792 (0.4563) acc 81.2500 (82.9688) lr 1.9686e-03 eta 2:28:57
epoch [6/50] batch [25/124] loss 0.2581 (0.4624) acc 92.1875 (82.7500) lr 1.9686e-03 eta 2:00:30
epoch [6/50] batch [30/124] loss 0.3245 (0.4462) acc 90.6250 (83.4896) lr 1.9686e-03 eta 1:41:31
epoch [6/50] batch [35/124] loss 0.4150 (0.4463) acc 87.5000 (83.6161) lr 1.9686e-03 eta 1:27:58
epoch [6/50] batch [40/124] loss 0.4075 (0.4474) acc 82.8125 (83.4766) lr 1.9686e-03 eta 1:17:48
epoch [6/50] batch [45/124] loss 0.4719 (0.4461) acc 79.6875 (83.4722) lr 1.9686e-03 eta 1:09:53
epoch [6/50] batch [50/124] loss 0.5845 (0.4491) acc 81.2500 (83.3750) lr 1.9686e-03 eta 1:03:32
epoch [6/50] batch [55/124] loss 0.4373 (0.4544) acc 85.9375 (83.2955) lr 1.9686e-03 eta 0:58:21
epoch [6/50] batch [60/124] loss 0.5317 (0.4571) acc 82.8125 (83.3854) lr 1.9686e-03 eta 0:54:01
epoch [6/50] batch [65/124] loss 0.5664 (0.4549) acc 76.5625 (83.5577) lr 1.9686e-03 eta 0:50:22
epoch [6/50] batch [70/124] loss 0.4277 (0.4631) acc 85.9375 (83.2589) lr 1.9686e-03 eta 0:47:13
epoch [6/50] batch [75/124] loss 0.6963 (0.4703) acc 67.1875 (82.8750) lr 1.9686e-03 eta 0:44:30
epoch [6/50] batch [80/124] loss 0.4878 (0.4702) acc 81.2500 (82.8516) lr 1.9686e-03 eta 0:42:08
epoch [6/50] batch [85/124] loss 0.5786 (0.4733) acc 75.0000 (82.5735) lr 1.9686e-03 eta 0:40:02
epoch [6/50] batch [90/124] loss 0.4734 (0.4718) acc 81.2500 (82.7257) lr 1.9686e-03 eta 0:38:11
epoch [6/50] batch [95/124] loss 0.4143 (0.4672) acc 85.9375 (82.9605) lr 1.9686e-03 eta 0:36:31
epoch [6/50] batch [100/124] loss 0.3831 (0.4672) acc 85.9375 (82.9062) lr 1.9686e-03 eta 0:35:02
epoch [6/50] batch [105/124] loss 0.5444 (0.4685) acc 78.1250 (82.7976) lr 1.9686e-03 eta 0:33:41
epoch [6/50] batch [110/124] loss 0.5249 (0.4662) acc 79.6875 (82.9261) lr 1.9686e-03 eta 0:32:27
epoch [6/50] batch [115/124] loss 0.2744 (0.4651) acc 87.5000 (82.9891) lr 1.9686e-03 eta 0:31:19
epoch [6/50] batch [120/124] loss 0.3276 (0.4622) acc 89.0625 (83.1250) lr 1.9686e-03 eta 0:30:17
epoch [7/50] batch [5/124] loss 0.6694 (0.4824) acc 76.5625 (82.8125) lr 1.9511e-03 eta 9:31:05
epoch [7/50] batch [10/124] loss 0.5127 (0.4665) acc 76.5625 (82.8125) lr 1.9511e-03 eta 4:48:46
epoch [7/50] batch [15/124] loss 0.5806 (0.4491) acc 75.0000 (83.4375) lr 1.9511e-03 eta 3:14:44
epoch [7/50] batch [20/124] loss 0.3501 (0.4469) acc 85.9375 (83.8281) lr 1.9511e-03 eta 2:27:43
epoch [7/50] batch [25/124] loss 0.2472 (0.4421) acc 95.3125 (84.0625) lr 1.9511e-03 eta 1:59:31
epoch [7/50] batch [30/124] loss 0.3020 (0.4389) acc 87.5000 (84.0625) lr 1.9511e-03 eta 1:40:42
epoch [7/50] batch [35/124] loss 0.5107 (0.4459) acc 81.2500 (83.7500) lr 1.9511e-03 eta 1:27:13
epoch [7/50] batch [40/124] loss 0.4519 (0.4527) acc 85.9375 (83.5547) lr 1.9511e-03 eta 1:17:08
epoch [7/50] batch [45/124] loss 0.4487 (0.4497) acc 87.5000 (83.5764) lr 1.9511e-03 eta 1:09:16
epoch [7/50] batch [50/124] loss 0.4023 (0.4507) acc 81.2500 (83.6562) lr 1.9511e-03 eta 1:02:58
epoch [7/50] batch [55/124] loss 0.3997 (0.4491) acc 84.3750 (83.7500) lr 1.9511e-03 eta 0:57:49
epoch [7/50] batch [60/124] loss 0.3804 (0.4536) acc 89.0625 (83.6979) lr 1.9511e-03 eta 0:53:33
epoch [7/50] batch [65/124] loss 0.4993 (0.4560) acc 79.6875 (83.4375) lr 1.9511e-03 eta 0:49:57
epoch [7/50] batch [70/124] loss 0.4375 (0.4544) acc 84.3750 (83.5045) lr 1.9511e-03 eta 0:46:52
epoch [7/50] batch [75/124] loss 0.5015 (0.4579) acc 84.3750 (83.4375) lr 1.9511e-03 eta 0:44:11
epoch [7/50] batch [80/124] loss 0.4856 (0.4606) acc 81.2500 (83.2617) lr 1.9511e-03 eta 0:41:50
epoch [7/50] batch [85/124] loss 0.4851 (0.4642) acc 79.6875 (83.0882) lr 1.9511e-03 eta 0:39:45
epoch [7/50] batch [90/124] loss 0.3333 (0.4643) acc 85.9375 (82.9340) lr 1.9511e-03 eta 0:37:54
epoch [7/50] batch [95/124] loss 0.3774 (0.4608) acc 87.5000 (83.1086) lr 1.9511e-03 eta 0:36:15
epoch [7/50] batch [100/124] loss 0.4573 (0.4634) acc 81.2500 (83.0312) lr 1.9511e-03 eta 0:34:45
