*** Config ***
***************
** Arguments **
***************
dataset: PACS
gpu: 0
model: CLIPAdapter
model_config_file: config/clipadapter.yaml
output_dir: output/CLIPAdapter-ViTB32-PACS-art_painting
root: ./data/
seed: 134
source_domains: ['cartoon', 'photo', 'sketch']
target_domains: ['art_painting']
************
** Config **
************
DATALOADER:
  NUM_WORKERS: 8
  TEST:
    BATCH_SIZE: 64
    SAMPLER: SequentialSampler
  TRAIN:
    BATCH_SIZE: 64
    SAMPLER: RandomSampler
DATASET:
  NAME: PACS
  ROOT: ./data/
  SOURCE_DOMAINS: ['cartoon', 'photo', 'sketch']
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ['art_painting']
GPU: 0
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ['random_resized_crop', 'random_flip', 'normalize']
MODEL:
  CLIPAdapter:
    BACKBONE: ViT-B/32
  NAME: CLIPAdapter
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: Cosine
  MAX_EPOCH: 2
  MOMENTUM: 0.9
  NAME: sgd
  SGD_DAMPENING: 0
  SGD_NESTEROV: False
  STEP_SIZE: -1
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/CLIPAdapter-ViTB32-PACS-art_painting
SEED: 134
TEST:
  EVALUATOR: Classification
  FINAL_Model: last_step
  SPLIT: Test
TRAIN:
  PRINT_FREQ: 5
Build Trainer: CLIPAdapter
Build Dataset: PACS
Transform for Train: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
Transform for Test: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    ToTensor()
    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
)
--------------  ------------------------------
Dataset         PACS
Source Domains  ['cartoon', 'photo', 'sketch']
Target Domains  ['art_painting']
# Classes       7
# Train Data    7,942
# Val Data      806
# Test Data     2,048
--------------  ------------------------------
Loading CLIP Backbone: ViT-B/32
Building Custom CLIP
{'original': ['a picture of a dog.', 'a picture of a elephant.', 'a picture of a giraffe.', 'a picture of a guitar.', 'a picture of a horse.', 'a picture of a house.', 'a picture of a person.'], 'cartoon': ['a picture of a cartoon dog.', 'a picture of a cartoon elephant.', 'a picture of a cartoon giraffe.', 'a picture of a cartoon guitar.', 'a picture of a cartoon horse.', 'a picture of a cartoon house.', 'a picture of a cartoon person.'], 'photo': ['a picture of a photo dog.', 'a picture of a photo elephant.', 'a picture of a photo giraffe.', 'a picture of a photo guitar.', 'a picture of a photo horse.', 'a picture of a photo house.', 'a picture of a photo person.'], 'sketch': ['a picture of a sketch dog.', 'a picture of a sketch elephant.', 'a picture of a sketch giraffe.', 'a picture of a sketch guitar.', 'a picture of a sketch horse.', 'a picture of a sketch house.', 'a picture of a sketch person.']}
Turning Off Gradients in Image and Text Encoder
Parameters to be updated: {'adapter.fc.2.weight', 'adapter.fc.0.weight'}
Build Evaluator: Classification
epoch [1/2] batch [5/124] loss 2.6230 (2.4641) acc 6.2500 (16.2500) lr 1.0000e-05 eta 0:03:20
epoch [1/2] batch [10/124] loss 2.4473 (2.4953) acc 14.0625 (14.3750) lr 1.0000e-05 eta 0:01:43
epoch [1/2] batch [15/124] loss 2.6621 (2.4552) acc 14.0625 (15.0000) lr 1.0000e-05 eta 0:01:11
epoch [1/2] batch [20/124] loss 2.1328 (2.4301) acc 20.3125 (16.1719) lr 1.0000e-05 eta 0:00:54
epoch [1/2] batch [25/124] loss 2.3809 (2.4195) acc 21.8750 (17.2500) lr 1.0000e-05 eta 0:00:44
epoch [1/2] batch [30/124] loss 2.3691 (2.4287) acc 26.5625 (17.3958) lr 1.0000e-05 eta 0:00:38
epoch [1/2] batch [35/124] loss 2.3027 (2.4179) acc 21.8750 (17.8125) lr 1.0000e-05 eta 0:00:33
epoch [1/2] batch [40/124] loss 2.4160 (2.4177) acc 15.6250 (17.6953) lr 1.0000e-05 eta 0:00:29
epoch [1/2] batch [45/124] loss 2.2988 (2.4152) acc 18.7500 (17.5000) lr 1.0000e-05 eta 0:00:26
epoch [1/2] batch [50/124] loss 2.2793 (2.4170) acc 20.3125 (17.4375) lr 1.0000e-05 eta 0:00:24
epoch [1/2] batch [55/124] loss 2.3047 (2.4271) acc 23.4375 (17.2159) lr 1.0000e-05 eta 0:00:22
epoch [1/2] batch [60/124] loss 2.0059 (2.4119) acc 23.4375 (17.5000) lr 1.0000e-05 eta 0:00:20
epoch [1/2] batch [65/124] loss 2.4648 (2.4246) acc 12.5000 (17.3077) lr 1.0000e-05 eta 0:00:19
epoch [1/2] batch [70/124] loss 2.6211 (2.4362) acc 20.3125 (17.2991) lr 1.0000e-05 eta 0:00:17
epoch [1/2] batch [75/124] loss 2.3613 (2.4366) acc 21.8750 (17.3125) lr 1.0000e-05 eta 0:00:16
epoch [1/2] batch [80/124] loss 2.3984 (2.4425) acc 14.0625 (17.1875) lr 1.0000e-05 eta 0:00:15
epoch [1/2] batch [85/124] loss 2.2832 (2.4387) acc 25.0000 (17.3162) lr 1.0000e-05 eta 0:00:14
epoch [1/2] batch [90/124] loss 2.1523 (2.4374) acc 23.4375 (17.2569) lr 1.0000e-05 eta 0:00:13
epoch [1/2] batch [95/124] loss 2.2695 (2.4360) acc 20.3125 (17.3191) lr 1.0000e-05 eta 0:00:13
epoch [1/2] batch [100/124] loss 2.5078 (2.4356) acc 10.9375 (17.4219) lr 1.0000e-05 eta 0:00:12
epoch [1/2] batch [105/124] loss 2.4121 (2.4361) acc 18.7500 (17.4107) lr 1.0000e-05 eta 0:00:11
epoch [1/2] batch [110/124] loss 2.4180 (2.4384) acc 18.7500 (17.3722) lr 1.0000e-05 eta 0:00:10
epoch [1/2] batch [115/124] loss 2.3887 (2.4366) acc 15.6250 (17.4049) lr 1.0000e-05 eta 0:00:10
epoch [1/2] batch [120/124] loss 2.5801 (2.4330) acc 21.8750 (17.5000) lr 1.0000e-05 eta 0:00:09
epoch [2/2] batch [5/124] loss 2.4531 (2.4672) acc 18.7500 (15.3125) lr 2.0000e-03 eta 0:00:30
epoch [2/2] batch [10/124] loss 2.5449 (2.3670) acc 9.3750 (15.4688) lr 2.0000e-03 eta 0:00:16
epoch [2/2] batch [15/124] loss 2.1875 (2.2900) acc 20.3125 (16.8750) lr 2.0000e-03 eta 0:00:11
epoch [2/2] batch [20/124] loss 2.1465 (2.2120) acc 9.3750 (17.2656) lr 2.0000e-03 eta 0:00:08
epoch [2/2] batch [25/124] loss 1.7500 (2.1200) acc 26.5625 (19.1875) lr 2.0000e-03 eta 0:00:06
epoch [2/2] batch [30/124] loss 1.3906 (2.0358) acc 39.0625 (21.7708) lr 2.0000e-03 eta 0:00:05
epoch [2/2] batch [35/124] loss 1.4258 (1.9345) acc 45.3125 (25.5357) lr 2.0000e-03 eta 0:00:04
epoch [2/2] batch [40/124] loss 0.8662 (1.8238) acc 73.4375 (30.1172) lr 2.0000e-03 eta 0:00:04
epoch [2/2] batch [45/124] loss 0.7979 (1.7233) acc 78.1250 (34.8611) lr 2.0000e-03 eta 0:00:03
epoch [2/2] batch [50/124] loss 0.6450 (1.6356) acc 78.1250 (38.6875) lr 2.0000e-03 eta 0:00:03
epoch [2/2] batch [55/124] loss 0.7251 (1.5486) acc 76.5625 (42.4432) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [60/124] loss 0.6582 (1.4725) acc 78.1250 (45.4688) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [65/124] loss 0.5068 (1.4096) acc 87.5000 (48.0048) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [70/124] loss 0.6870 (1.3542) acc 82.8125 (50.2902) lr 2.0000e-03 eta 0:00:02
epoch [2/2] batch [75/124] loss 0.6689 (1.3031) acc 73.4375 (52.1667) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [80/124] loss 0.5518 (1.2599) acc 85.9375 (53.9453) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [85/124] loss 0.5957 (1.2213) acc 85.9375 (55.4412) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [90/124] loss 0.3286 (1.1800) acc 92.1875 (57.1701) lr 2.0000e-03 eta 0:00:01
epoch [2/2] batch [95/124] loss 0.4707 (1.1479) acc 84.3750 (58.3717) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [100/124] loss 0.4221 (1.1173) acc 85.9375 (59.5938) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [105/124] loss 0.5249 (1.0903) acc 81.2500 (60.5952) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [110/124] loss 0.3613 (1.0624) acc 90.6250 (61.7045) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [115/124] loss 0.5557 (1.0385) acc 79.6875 (62.5543) lr 2.0000e-03 eta 0:00:00
epoch [2/2] batch [120/124] loss 0.5352 (1.0182) acc 87.5000 (63.3594) lr 2.0000e-03 eta 0:00:00
Model Saved to: output/CLIPAdapter-ViTB32-PACS-art_painting/model.pth.tar-2
Finish Training
Evaluate on the Test Set
{'original': ['a picture of a dog.', 'a picture of a elephant.', 'a picture of a giraffe.', 'a picture of a guitar.', 'a picture of a horse.', 'a picture of a house.', 'a picture of a person.'], 'art_painting': ['a picture of a art painting dog.', 'a picture of a art painting elephant.', 'a picture of a art painting giraffe.', 'a picture of a art painting guitar.', 'a picture of a art painting horse.', 'a picture of a art painting house.', 'a picture of a art painting person.']}
{'original': tensor([[ 0.0130,  0.0088, -0.0393,  ..., -0.0427, -0.0132,  0.0195],
        [ 0.0052,  0.0047, -0.0052,  ..., -0.0147,  0.0049,  0.0210],
        [ 0.0317, -0.0136, -0.0396,  ..., -0.0195, -0.0196, -0.0251],
        ...,
        [ 0.0157, -0.0074, -0.0182,  ..., -0.0357, -0.0072,  0.0031],
        [ 0.0065,  0.0099, -0.0113,  ..., -0.0518, -0.0119, -0.0191],
        [ 0.0049,  0.0079, -0.0011,  ..., -0.0593, -0.0150, -0.0024]],
       device='cuda:0', dtype=torch.float16), 'art_painting': tensor([[ 0.0347, -0.0056, -0.0271,  ..., -0.0314, -0.0006, -0.0018],
        [ 0.0241, -0.0111, -0.0080,  ...,  0.0004,  0.0161,  0.0137],
        [ 0.0443, -0.0284, -0.0266,  ..., -0.0101, -0.0107, -0.0369],
        ...,
        [ 0.0286, -0.0029, -0.0031,  ..., -0.0210, -0.0044, -0.0133],
        [ 0.0182,  0.0093, -0.0034,  ..., -0.0334, -0.0260, -0.0240],
        [ 0.0221, -0.0028,  0.0012,  ..., -0.0517, -0.0204, -0.0329]],
       device='cuda:0', dtype=torch.float16)}
----------  ------
Total #     2,048
Correct #   1,970
Accuracy    96.19%
Error Rate  3.81%
Macro_F1    96.04%
----------  ------
